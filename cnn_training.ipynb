{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import importlib\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from utils import load_torch, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(load_torch)\n",
    "\n",
    "data_folder = \"quickdraw/train_simplified/\"\n",
    "access_file_generator = map(lambda x : data_folder + x + '.csv', load.classes)\n",
    "trainGenerator = load_torch.ImageLoader(load.classes_1+load.classes_2+load.classes_3+load.classes_4, data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = trainGenerator.__iter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: torch.Size([16, 1, 32, 32])\n",
      "y.shape: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "X, y = next(gen)\n",
    "print('X.shape:', X.shape)\n",
    "print('y.shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building PyTorch CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as ag\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class VanillaDoodle(nn.Module):\n",
    "    # Here we define our network structure\n",
    "    name=\"doodle-vanilla\"\n",
    "    def __init__(self, cdim=8):\n",
    "        super(VanillaDoodle, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3).double() \n",
    "        self.conv2 = nn.Conv2d(6,16, 3).double()\n",
    "        self.conv3 = nn.Conv2d(16,32,3).double()\n",
    "        self.conv4 = nn.Conv2d(32,64,3).double()\n",
    "        self.fc1   = nn.Linear(128,120).double()\n",
    "        self.fc2   = nn.Linear(120, 84).double() \n",
    "        self.fc3   = nn.Linear(84,cdim).double()\n",
    "        \n",
    "    # Here we define one forward pass through the network\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "        x = x.view(-1, int(self.num_flat_features(x)))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    # Determine the number of features in a batch of tensors\n",
    "    def num_flat_features(self, x): \n",
    "        size = x.size()\n",
    "        return np.prod(size[1:])\n",
    "\n",
    "\n",
    "#net = VanillaDoodle(cdim=len(load.classes_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code derived from: https://github.com/pytorch/vision/blob/master/torchvision/models/inception.py\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "class InceptionModule(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(InceptionModule, self).__init__()\n",
    "        self.branch1x1 = BasicConv2d(in_channels, 12, kernel_size=1)\n",
    "\n",
    "        self.branch3x3_1 = BasicConv2d(in_channels, 24, kernel_size=1)\n",
    "        self.branch3x3_2a = BasicConv2d(24, 24, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.branch3x3_2b = BasicConv2d(24, 24, kernel_size=(3, 1), padding=(1, 0))\n",
    "\n",
    "        self.branch3x3dbl_1 = BasicConv2d(in_channels, 32, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = BasicConv2d(32, 24, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3a = BasicConv2d(24, 24, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.branch3x3dbl_3b = BasicConv2d(24, 24, kernel_size=(3, 1), padding=(1, 0))\n",
    "\n",
    "        self.branch_pool = BasicConv2d(in_channels, 16, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = [\n",
    "            self.branch3x3_2a(branch3x3),\n",
    "            self.branch3x3_2b(branch3x3),\n",
    "        ]\n",
    "        branch3x3 = torch.cat(branch3x3, 1)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = [\n",
    "            self.branch3x3dbl_3a(branch3x3dbl),\n",
    "            self.branch3x3dbl_3b(branch3x3dbl),\n",
    "        ]\n",
    "        branch3x3dbl = torch.cat(branch3x3dbl, 1)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch3x3, branch3x3dbl, branch_pool]\n",
    "        return torch.cat(outputs, 1)\n",
    "    \n",
    "class DoodleInception(nn.Module):\n",
    "    # Here we define our network structure\n",
    "    name=\"doodle-inception\"\n",
    "    def __init__(self, cdim=8):\n",
    "        super(DoodleInception, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3).double() \n",
    "        self.mod1  = InceptionModule(6).double()\n",
    "        self.conv2 = nn.Conv2d(124, 128, 3).double()\n",
    "        self.fc1   = nn.Linear(512,128).double()\n",
    "        self.fc2   = nn.Linear(128,cdim).double()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.mod1(x)), (2, 2))  #?x124x7x7\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))  #?x128x2x2\n",
    "        x = x.view(-1, int(self.num_flat_features(x)))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    # Determine the number of features in a batch of tensors\n",
    "    def num_flat_features(self, x): \n",
    "        size = x.size()\n",
    "        return np.prod(size[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "DoodleInception(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (mod1): InceptionModule(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(6, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(12, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(24, 24, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(24, 24, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(6, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(32, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(24, 24, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(24, 24, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(6, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (conv2): Conv2d(124, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "B     = 128              # Minibatch size\n",
    "T     = 10               # Number of epochs\n",
    "gamma = .001             # learning rate\n",
    "rho   = .9               # momentum\n",
    "\n",
    "classes = load.classes_1+load.classes_2+load.classes_3+load.classes_4\n",
    "print(len(classes))\n",
    "    \n",
    "net = DoodleInception(cdim=len(classes))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "    net.parameters(),\n",
    "    lr=gamma,\n",
    "    momentum=rho\n",
    ")\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch:  7\n",
      "current step:  15799\n",
      "DoodleInception(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (mod1): InceptionModule(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(6, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(12, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(24, 24, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(24, 24, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(6, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(32, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(24, 24, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(24, 24, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(6, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (conv2): Conv2d(124, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# use this code when starting training after connection loss\n",
    "import pickle\n",
    "\n",
    "with open(\"Inception CNN/32 classes/inception_cnn_32_training_acc\", 'rb') as f:\n",
    "    trainingAcc = pickle.load(f)\n",
    "with open(\"Inception CNN/32 classes/inception_cnn_32_training_loss\", 'rb') as f:\n",
    "    trainingLoss = pickle.load(f)\n",
    "with open(\"Inception CNN/32 classes/inception_cnn_32_val_acc\", 'rb') as f:\n",
    "    testingAcc = pickle.load(f)\n",
    "with open(\"Inception CNN/32 classes/inception_cnn_32_val_loss\", 'rb') as f:\n",
    "    testingLoss = pickle.load(f)\n",
    "    \n",
    "with open(\"Inception CNN/32 classes/current_epoch\", 'rb') as f:\n",
    "    current_epoch = pickle.load(f)\n",
    "print(\"current epoch: \",current_epoch)\n",
    "with open(\"Inception CNN/32 classes/current_step\", 'rb') as f:\n",
    "    current_step = pickle.load(f)\n",
    "print(\"current step: \",current_step)\n",
    "\n",
    "classes = load.classes_1+load.classes_2+load.classes_3+load.classes_4\n",
    "net = DoodleInception(cdim=len(classes))\n",
    "net.load_state_dict(torch.load(\"Inception CNN/32 classes/inception_cnn_32.pt\"))\n",
    "net.eval()\n",
    "print(net)\n",
    "\n",
    "B     = 128              # Minibatch size\n",
    "T     = 10     \n",
    "gamma = .001             # learning rate\n",
    "rho   = .9               # momentum\n",
    "   \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "    net.parameters(),\n",
    "    lr=gamma,\n",
    "    momentum=rho\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [100], Loss: 0.7237 (val:0.5330), Accuracy:78.33% (val:86.67%)\n",
      "Epoch [8/10], Step [200], Loss: 0.5782 (val:0.6182), Accuracy:85.00% (val:83.33%)\n",
      "Epoch [8/10], Step [300], Loss: 0.5237 (val:0.4500), Accuracy:84.17% (val:86.67%)\n",
      "Epoch [8/10], Step [400], Loss: 0.7198 (val:0.4666), Accuracy:77.50% (val:83.33%)\n",
      "Epoch [8/10], Step [500], Loss: 0.6553 (val:0.7166), Accuracy:85.00% (val:86.67%)\n",
      "Epoch [8/10], Step [600], Loss: 0.7716 (val:0.5298), Accuracy:82.50% (val:83.33%)\n",
      "Epoch [8/10], Step [700], Loss: 0.3799 (val:0.5540), Accuracy:90.91% (val:88.00%)\n",
      "Epoch [8/10], Step [800], Loss: 0.5400 (val:0.7263), Accuracy:83.33% (val:80.00%)\n",
      "Epoch [8/10], Step [900], Loss: 0.4407 (val:0.7028), Accuracy:85.83% (val:80.00%)\n",
      "Epoch [8/10], Step [1000], Loss: 0.5869 (val:0.1771), Accuracy:81.67% (val:93.33%)\n",
      "Epoch [8/10], Step [1100], Loss: 0.5874 (val:0.6388), Accuracy:87.50% (val:80.00%)\n",
      "Epoch [8/10], Step [1200], Loss: 0.5200 (val:0.5608), Accuracy:88.33% (val:90.00%)\n",
      "Epoch [8/10], Step [1300], Loss: 0.5245 (val:0.3367), Accuracy:84.17% (val:90.00%)\n",
      "Epoch [8/10], Step [1400], Loss: 0.5878 (val:0.5879), Accuracy:82.83% (val:80.00%)\n",
      "Epoch [8/10], Step [1500], Loss: 0.5522 (val:0.5627), Accuracy:84.17% (val:86.67%)\n",
      "Epoch [8/10], Step [1600], Loss: 0.4498 (val:0.3382), Accuracy:87.50% (val:90.00%)\n",
      "Epoch [8/10], Step [1700], Loss: 0.4072 (val:0.9325), Accuracy:87.50% (val:63.33%)\n",
      "Epoch [8/10], Step [1800], Loss: 0.6131 (val:1.0155), Accuracy:84.17% (val:66.67%)\n",
      "Epoch [8/10], Step [1900], Loss: 0.8567 (val:0.4687), Accuracy:76.67% (val:80.00%)\n",
      "Epoch [8/10], Step [2000], Loss: 0.6260 (val:0.8227), Accuracy:86.67% (val:76.67%)\n",
      "Epoch [8/10], Step [2100], Loss: 0.3762 (val:0.5679), Accuracy:90.91% (val:84.00%)\n",
      "Epoch [8/10], Step [2200], Loss: 0.5260 (val:0.4922), Accuracy:82.50% (val:90.00%)\n",
      "Epoch [8/10], Step [2300], Loss: 0.6171 (val:0.5506), Accuracy:80.83% (val:86.67%)\n",
      "Epoch [8/10], Step [2400], Loss: 0.6166 (val:0.4870), Accuracy:85.00% (val:83.33%)\n",
      "Epoch [8/10], Step [2500], Loss: 0.5605 (val:0.6859), Accuracy:85.00% (val:80.00%)\n",
      "Epoch [8/10], Step [2600], Loss: 0.5242 (val:0.5267), Accuracy:87.50% (val:80.00%)\n",
      "Epoch [8/10], Step [2700], Loss: 0.4517 (val:0.1702), Accuracy:87.50% (val:93.33%)\n",
      "Epoch [8/10], Step [2800], Loss: 0.6844 (val:0.4372), Accuracy:85.86% (val:88.00%)\n",
      "Epoch [8/10], Step [2900], Loss: 0.5003 (val:0.1648), Accuracy:85.83% (val:96.67%)\n",
      "Epoch [8/10], Step [3000], Loss: 0.4145 (val:0.1518), Accuracy:86.67% (val:96.67%)\n",
      "Epoch [8/10], Step [3100], Loss: 0.6233 (val:0.9891), Accuracy:86.67% (val:76.67%)\n",
      "Epoch [8/10], Step [3200], Loss: 0.6795 (val:0.5145), Accuracy:80.00% (val:80.00%)\n",
      "Epoch [8/10], Step [3300], Loss: 0.4597 (val:1.0792), Accuracy:85.83% (val:80.00%)\n",
      "Epoch [8/10], Step [3400], Loss: 0.5796 (val:0.4987), Accuracy:80.83% (val:80.00%)\n",
      "Epoch [8/10], Step [3500], Loss: 0.9794 (val:0.8285), Accuracy:71.72% (val:68.00%)\n",
      "Epoch [8/10], Step [3600], Loss: 0.6343 (val:0.2858), Accuracy:82.50% (val:86.67%)\n",
      "Epoch [8/10], Step [3700], Loss: 0.4949 (val:0.3944), Accuracy:84.17% (val:90.00%)\n",
      "Epoch [8/10], Step [3800], Loss: 0.4745 (val:0.4860), Accuracy:83.33% (val:86.67%)\n",
      "Epoch [8/10], Step [3900], Loss: 0.8044 (val:0.3065), Accuracy:80.00% (val:93.33%)\n",
      "Epoch [8/10], Step [4000], Loss: 0.8226 (val:1.1521), Accuracy:82.50% (val:70.00%)\n",
      "Epoch [8/10], Step [4100], Loss: 0.4311 (val:0.5239), Accuracy:87.50% (val:80.00%)\n",
      "Epoch [8/10], Step [4200], Loss: 0.6726 (val:0.4294), Accuracy:81.82% (val:88.00%)\n",
      "Epoch [8/10], Step [4300], Loss: 0.6970 (val:0.3506), Accuracy:80.83% (val:90.00%)\n",
      "Epoch [8/10], Step [4400], Loss: 0.3984 (val:0.3557), Accuracy:87.50% (val:90.00%)\n",
      "Epoch [8/10], Step [4500], Loss: 0.6051 (val:0.8072), Accuracy:85.00% (val:73.33%)\n",
      "Epoch [8/10], Step [4600], Loss: 0.7491 (val:0.6295), Accuracy:77.50% (val:86.67%)\n",
      "Epoch [8/10], Step [4700], Loss: 0.7473 (val:0.6985), Accuracy:83.33% (val:83.33%)\n",
      "Epoch [8/10], Step [4800], Loss: 0.7586 (val:0.4281), Accuracy:80.00% (val:93.33%)\n",
      "Epoch [8/10], Step [4900], Loss: 0.3533 (val:0.8573), Accuracy:88.89% (val:72.00%)\n",
      "Epoch [8/10], Step [5000], Loss: 0.6822 (val:0.4738), Accuracy:83.33% (val:90.00%)\n",
      "Epoch [8/10], Step [5100], Loss: 0.8209 (val:0.2857), Accuracy:80.83% (val:90.00%)\n",
      "Epoch [8/10], Step [5200], Loss: 0.4460 (val:0.4216), Accuracy:88.33% (val:90.00%)\n",
      "Epoch [8/10], Step [5300], Loss: 0.6080 (val:0.4578), Accuracy:80.00% (val:90.00%)\n",
      "Epoch [8/10], Step [5400], Loss: 0.7509 (val:0.5565), Accuracy:80.83% (val:83.33%)\n",
      "Epoch [8/10], Step [5500], Loss: 0.7833 (val:0.4776), Accuracy:80.00% (val:86.67%)\n",
      "Epoch [8/10], Step [5600], Loss: 0.9077 (val:0.2482), Accuracy:78.79% (val:92.00%)\n",
      "Epoch [8/10], Step [5700], Loss: 0.5964 (val:0.7818), Accuracy:86.67% (val:86.67%)\n",
      "Epoch [8/10], Step [5800], Loss: 0.7418 (val:0.8853), Accuracy:77.50% (val:86.67%)\n",
      "Epoch [8/10], Step [5900], Loss: 0.6625 (val:0.5931), Accuracy:84.17% (val:86.67%)\n",
      "Epoch [8/10], Step [6000], Loss: 0.5454 (val:0.4859), Accuracy:85.00% (val:83.33%)\n",
      "Epoch [8/10], Step [6100], Loss: 0.5022 (val:0.6289), Accuracy:83.33% (val:80.00%)\n",
      "Epoch [8/10], Step [6200], Loss: 0.7067 (val:0.6664), Accuracy:80.83% (val:76.67%)\n",
      "Epoch [8/10], Step [6300], Loss: 0.6944 (val:0.2913), Accuracy:76.77% (val:92.00%)\n",
      "Epoch [8/10], Step [6400], Loss: 0.8079 (val:0.7499), Accuracy:78.33% (val:73.33%)\n",
      "Epoch [8/10], Step [6500], Loss: 0.6190 (val:0.7059), Accuracy:83.33% (val:83.33%)\n",
      "Epoch [8/10], Step [6600], Loss: 0.3778 (val:0.3384), Accuracy:87.50% (val:93.33%)\n",
      "Epoch [8/10], Step [6700], Loss: 0.5618 (val:0.5560), Accuracy:80.83% (val:86.67%)\n",
      "Epoch [8/10], Step [6800], Loss: 0.4856 (val:0.6846), Accuracy:85.00% (val:83.33%)\n",
      "Epoch [8/10], Step [6900], Loss: 0.4662 (val:0.7829), Accuracy:90.00% (val:83.33%)\n",
      "Epoch [8/10], Step [7000], Loss: 0.5623 (val:1.1489), Accuracy:84.85% (val:76.00%)\n",
      "Epoch [8/10], Step [7100], Loss: 0.6471 (val:0.5676), Accuracy:83.33% (val:80.00%)\n",
      "Epoch [8/10], Step [7200], Loss: 0.6214 (val:0.3350), Accuracy:82.50% (val:86.67%)\n",
      "Epoch [8/10], Step [7300], Loss: 0.6474 (val:0.5529), Accuracy:82.50% (val:86.67%)\n",
      "Epoch [8/10], Step [7400], Loss: 0.6467 (val:0.4601), Accuracy:80.83% (val:86.67%)\n",
      "Epoch [8/10], Step [7500], Loss: 0.5439 (val:1.1530), Accuracy:86.67% (val:76.67%)\n",
      "Epoch [8/10], Step [7600], Loss: 0.6324 (val:0.3001), Accuracy:81.67% (val:93.33%)\n",
      "Epoch [8/10], Step [7700], Loss: 0.6244 (val:1.0976), Accuracy:83.84% (val:60.00%)\n",
      "Epoch [8/10], Step [7800], Loss: 0.7792 (val:0.6248), Accuracy:78.33% (val:83.33%)\n",
      "Epoch [8/10], Step [7900], Loss: 0.4001 (val:0.6385), Accuracy:89.17% (val:80.00%)\n",
      "Epoch [8/10], Step [8000], Loss: 0.5512 (val:0.5369), Accuracy:85.00% (val:86.67%)\n",
      "Epoch [8/10], Step [8100], Loss: 0.4279 (val:0.8448), Accuracy:87.50% (val:76.67%)\n",
      "Epoch [8/10], Step [8200], Loss: 0.6578 (val:0.2860), Accuracy:81.67% (val:86.67%)\n",
      "Epoch [8/10], Step [8300], Loss: 0.6101 (val:0.5876), Accuracy:85.00% (val:83.33%)\n",
      "Epoch [8/10], Step [8400], Loss: 0.5339 (val:0.5798), Accuracy:84.85% (val:88.00%)\n",
      "Epoch [8/10], Step [8500], Loss: 0.6200 (val:0.4399), Accuracy:80.83% (val:86.67%)\n",
      "Epoch [8/10], Step [8600], Loss: 0.6479 (val:0.5383), Accuracy:82.50% (val:83.33%)\n",
      "Epoch [8/10], Step [8700], Loss: 0.5336 (val:0.6412), Accuracy:83.33% (val:80.00%)\n",
      "Epoch [8/10], Step [8800], Loss: 0.6625 (val:0.5140), Accuracy:83.33% (val:83.33%)\n",
      "Epoch [8/10], Step [8900], Loss: 0.5942 (val:0.5541), Accuracy:82.50% (val:90.00%)\n",
      "Epoch [8/10], Step [9000], Loss: 0.7163 (val:0.9227), Accuracy:80.00% (val:73.33%)\n",
      "Epoch [8/10], Step [9100], Loss: 0.5023 (val:0.8746), Accuracy:86.87% (val:84.00%)\n",
      "Epoch [8/10], Step [9200], Loss: 0.5074 (val:0.3062), Accuracy:87.50% (val:93.33%)\n",
      "Epoch [8/10], Step [9300], Loss: 0.6631 (val:0.5756), Accuracy:81.67% (val:83.33%)\n",
      "Epoch [8/10], Step [9400], Loss: 0.5183 (val:0.4291), Accuracy:83.33% (val:86.67%)\n",
      "Epoch [8/10], Step [9500], Loss: 0.6264 (val:0.6183), Accuracy:83.33% (val:86.67%)\n",
      "Epoch [8/10], Step [9600], Loss: 0.4895 (val:0.5342), Accuracy:85.00% (val:83.33%)\n",
      "Epoch [8/10], Step [9700], Loss: 0.4849 (val:0.5666), Accuracy:88.33% (val:86.67%)\n",
      "Epoch [8/10], Step [9800], Loss: 0.4606 (val:0.5536), Accuracy:88.89% (val:88.00%)\n",
      "Epoch [8/10], Step [9900], Loss: 0.6268 (val:0.6503), Accuracy:85.83% (val:86.67%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [10000], Loss: 0.5618 (val:0.8006), Accuracy:88.33% (val:86.67%)\n",
      "Epoch [8/10], Step [10100], Loss: 0.6025 (val:0.6384), Accuracy:78.33% (val:83.33%)\n",
      "Epoch [8/10], Step [10200], Loss: 0.8027 (val:0.7720), Accuracy:80.00% (val:80.00%)\n",
      "Epoch [8/10], Step [10300], Loss: 0.6569 (val:0.5504), Accuracy:86.67% (val:86.67%)\n",
      "Epoch [8/10], Step [10400], Loss: 0.7000 (val:1.0486), Accuracy:78.33% (val:76.67%)\n",
      "Epoch [8/10], Step [10500], Loss: 0.7943 (val:0.6517), Accuracy:79.80% (val:84.00%)\n",
      "Epoch [8/10], Step [10600], Loss: 0.5948 (val:1.0273), Accuracy:82.50% (val:73.33%)\n",
      "Epoch [8/10], Step [10700], Loss: 0.6799 (val:0.3741), Accuracy:80.83% (val:83.33%)\n",
      "Epoch [8/10], Step [10800], Loss: 0.6706 (val:0.5278), Accuracy:82.50% (val:76.67%)\n",
      "Epoch [8/10], Step [10900], Loss: 0.5169 (val:1.5160), Accuracy:84.17% (val:70.00%)\n",
      "Epoch [8/10], Step [11000], Loss: 0.6431 (val:0.6732), Accuracy:84.17% (val:83.33%)\n",
      "Epoch [8/10], Step [11100], Loss: 0.5176 (val:0.7170), Accuracy:83.33% (val:86.67%)\n",
      "Epoch [8/10], Step [11200], Loss: 0.5201 (val:1.0944), Accuracy:86.87% (val:68.00%)\n",
      "Epoch [8/10], Step [11300], Loss: 0.6416 (val:0.3679), Accuracy:80.83% (val:86.67%)\n",
      "Epoch [8/10], Step [11400], Loss: 0.7968 (val:0.6856), Accuracy:80.00% (val:76.67%)\n",
      "Epoch [8/10], Step [11500], Loss: 0.5676 (val:0.5387), Accuracy:87.50% (val:83.33%)\n",
      "Epoch [8/10], Step [11600], Loss: 0.5844 (val:0.3123), Accuracy:85.83% (val:93.33%)\n",
      "Epoch [8/10], Step [11700], Loss: 0.7134 (val:1.1248), Accuracy:82.50% (val:73.33%)\n",
      "Epoch [8/10], Step [11800], Loss: 0.6079 (val:0.9263), Accuracy:80.00% (val:73.33%)\n",
      "Epoch [8/10], Step [11900], Loss: 0.5837 (val:0.5437), Accuracy:88.89% (val:80.00%)\n",
      "Epoch [8/10], Step [12000], Loss: 0.6279 (val:0.6141), Accuracy:85.00% (val:76.67%)\n",
      "Epoch [8/10], Step [12100], Loss: 0.6002 (val:0.5372), Accuracy:85.83% (val:90.00%)\n",
      "Epoch [8/10], Step [12200], Loss: 0.4356 (val:0.5823), Accuracy:85.00% (val:80.00%)\n",
      "Epoch [8/10], Step [12300], Loss: 0.4627 (val:0.9561), Accuracy:86.67% (val:70.00%)\n",
      "Epoch [8/10], Step [12400], Loss: 0.6040 (val:0.5801), Accuracy:80.83% (val:90.00%)\n",
      "Epoch [8/10], Step [12500], Loss: 0.4788 (val:0.3347), Accuracy:85.83% (val:90.00%)\n",
      "Epoch [8/10], Step [12600], Loss: 0.5301 (val:0.3475), Accuracy:79.80% (val:96.00%)\n",
      "Epoch [8/10], Step [12700], Loss: 0.5816 (val:0.7817), Accuracy:83.33% (val:73.33%)\n",
      "Epoch [8/10], Step [12800], Loss: 0.4977 (val:0.4987), Accuracy:87.50% (val:83.33%)\n",
      "Epoch [8/10], Step [12900], Loss: 0.4655 (val:0.4477), Accuracy:86.67% (val:93.33%)\n",
      "Epoch [8/10], Step [13000], Loss: 0.7365 (val:0.1764), Accuracy:79.17% (val:96.67%)\n",
      "Epoch [8/10], Step [13100], Loss: 0.6080 (val:0.4537), Accuracy:84.17% (val:90.00%)\n",
      "Epoch [8/10], Step [13200], Loss: 0.4970 (val:0.6624), Accuracy:86.67% (val:76.67%)\n",
      "Epoch [8/10], Step [13300], Loss: 0.6014 (val:0.5440), Accuracy:79.80% (val:88.00%)\n",
      "Epoch [8/10], Step [13400], Loss: 0.3604 (val:0.4001), Accuracy:85.83% (val:83.33%)\n",
      "Epoch [8/10], Step [13500], Loss: 0.5254 (val:0.4943), Accuracy:85.83% (val:86.67%)\n",
      "Epoch [8/10], Step [13600], Loss: 0.6223 (val:0.4702), Accuracy:80.00% (val:86.67%)\n",
      "Epoch [8/10], Step [13700], Loss: 0.7957 (val:0.6229), Accuracy:78.33% (val:80.00%)\n",
      "Epoch [8/10], Step [13800], Loss: 0.6832 (val:0.4015), Accuracy:80.83% (val:86.67%)\n",
      "Epoch [8/10], Step [13900], Loss: 0.6773 (val:1.3101), Accuracy:81.67% (val:76.67%)\n",
      "Epoch [8/10], Step [14000], Loss: 0.7238 (val:0.5504), Accuracy:84.85% (val:88.00%)\n",
      "Epoch [8/10], Step [14100], Loss: 0.5924 (val:0.6480), Accuracy:81.67% (val:83.33%)\n",
      "Epoch [8/10], Step [14200], Loss: 0.5248 (val:0.4139), Accuracy:87.50% (val:86.67%)\n",
      "Epoch [8/10], Step [14300], Loss: 0.6697 (val:0.8350), Accuracy:78.33% (val:80.00%)\n",
      "Epoch [8/10], Step [14400], Loss: 0.6381 (val:0.1511), Accuracy:83.33% (val:100.00%)\n",
      "Epoch [8/10], Step [14500], Loss: 0.7587 (val:0.5199), Accuracy:75.83% (val:86.67%)\n",
      "Epoch [8/10], Step [14600], Loss: 0.5515 (val:0.4420), Accuracy:81.67% (val:86.67%)\n",
      "Epoch [8/10], Step [14700], Loss: 0.3874 (val:0.6152), Accuracy:87.88% (val:84.00%)\n",
      "Epoch [8/10], Step [14800], Loss: 0.6690 (val:0.6081), Accuracy:78.33% (val:80.00%)\n",
      "Epoch [8/10], Step [14900], Loss: 0.6564 (val:0.8161), Accuracy:80.83% (val:86.67%)\n",
      "Epoch [8/10], Step [15000], Loss: 0.5501 (val:0.3306), Accuracy:85.00% (val:90.00%)\n",
      "Epoch [8/10], Step [15100], Loss: 0.7648 (val:0.6470), Accuracy:80.00% (val:76.67%)\n",
      "Epoch [8/10], Step [15200], Loss: 0.4668 (val:0.5520), Accuracy:85.00% (val:86.67%)\n",
      "Epoch [8/10], Step [15300], Loss: 0.7945 (val:0.6612), Accuracy:80.00% (val:93.33%)\n",
      "Epoch [8/10], Step [15400], Loss: 0.6523 (val:0.8798), Accuracy:78.79% (val:72.00%)\n",
      "Epoch [8/10], Step [15500], Loss: 0.5739 (val:0.7735), Accuracy:86.67% (val:70.00%)\n",
      "Epoch [8/10], Step [15600], Loss: 0.5525 (val:0.6886), Accuracy:84.17% (val:83.33%)\n",
      "Epoch [8/10], Step [15700], Loss: 0.6189 (val:0.3557), Accuracy:84.17% (val:93.33%)\n",
      "Epoch [8/10], Step [15800], Loss: 0.5611 (val:0.7164), Accuracy:83.33% (val:76.67%)\n",
      "Epoch [8/10], Step [15900], Loss: 0.5756 (val:0.7048), Accuracy:84.17% (val:86.67%)\n",
      "Epoch [8/10], Step [16000], Loss: 0.4722 (val:0.4514), Accuracy:88.33% (val:86.67%)\n",
      "Epoch [8/10], Step [16100], Loss: 0.4435 (val:0.3746), Accuracy:86.87% (val:92.00%)\n",
      "Epoch [8/10], Step [16200], Loss: 0.7146 (val:0.3807), Accuracy:84.17% (val:86.67%)\n",
      "Epoch [8/10], Step [16300], Loss: 0.5806 (val:0.8660), Accuracy:82.50% (val:83.33%)\n",
      "Epoch [8/10], Step [16400], Loss: 0.5706 (val:0.6385), Accuracy:82.50% (val:80.00%)\n",
      "Epoch [8/10], Step [16500], Loss: 0.3340 (val:0.5480), Accuracy:89.17% (val:80.00%)\n",
      "Epoch [8/10], Step [16600], Loss: 0.5993 (val:0.4584), Accuracy:82.50% (val:80.00%)\n",
      "Epoch [8/10], Step [16700], Loss: 0.4494 (val:0.4656), Accuracy:85.00% (val:90.00%)\n",
      "Epoch [8/10], Step [16800], Loss: 0.5746 (val:0.5015), Accuracy:78.79% (val:84.00%)\n",
      "Epoch [8/10], Step [16900], Loss: 0.7382 (val:0.6404), Accuracy:77.50% (val:76.67%)\n",
      "Epoch [8/10], Step [17000], Loss: 0.5965 (val:0.6193), Accuracy:83.33% (val:80.00%)\n",
      "Epoch [8/10], Step [17100], Loss: 0.5979 (val:0.5782), Accuracy:83.33% (val:83.33%)\n",
      "Epoch [8/10], Step [17200], Loss: 0.5469 (val:0.3072), Accuracy:85.83% (val:90.00%)\n",
      "Epoch [8/10], Step [17300], Loss: 0.6252 (val:0.8741), Accuracy:81.67% (val:80.00%)\n",
      "Epoch [8/10], Step [17400], Loss: 0.4374 (val:0.5493), Accuracy:86.67% (val:83.33%)\n",
      "Epoch [8/10], Step [17500], Loss: 0.5446 (val:0.4588), Accuracy:83.84% (val:84.00%)\n",
      "Epoch [8/10], Step [17600], Loss: 0.4579 (val:0.5619), Accuracy:91.67% (val:86.67%)\n",
      "Epoch [8/10], Step [17700], Loss: 0.5759 (val:0.8505), Accuracy:86.67% (val:73.33%)\n",
      "Epoch [8/10], Step [17800], Loss: 0.5731 (val:0.6524), Accuracy:85.00% (val:90.00%)\n",
      "Epoch [8/10], Step [17900], Loss: 0.5532 (val:0.7941), Accuracy:80.83% (val:76.67%)\n",
      "Epoch [8/10], Step [18000], Loss: 0.4991 (val:0.5249), Accuracy:85.83% (val:83.33%)\n",
      "Epoch [8/10], Step [18100], Loss: 0.5370 (val:0.4864), Accuracy:86.67% (val:90.00%)\n",
      "Epoch [8/10], Step [18200], Loss: 0.5368 (val:0.5931), Accuracy:87.88% (val:80.00%)\n",
      "Epoch [8/10], Step [18300], Loss: 0.7378 (val:0.4674), Accuracy:79.17% (val:83.33%)\n",
      "Epoch [8/10], Step [18400], Loss: 0.7369 (val:0.7416), Accuracy:80.83% (val:80.00%)\n",
      "Epoch [8/10], Step [18500], Loss: 0.6836 (val:0.7786), Accuracy:80.00% (val:70.00%)\n",
      "Epoch [8/10], Step [18600], Loss: 0.7460 (val:0.4981), Accuracy:81.67% (val:80.00%)\n",
      "Epoch [8/10], Step [18700], Loss: 0.6325 (val:0.7192), Accuracy:79.17% (val:80.00%)\n",
      "Epoch [8/10], Step [18800], Loss: 0.6348 (val:0.5751), Accuracy:82.50% (val:80.00%)\n",
      "Epoch [8/10], Step [18900], Loss: 0.5318 (val:0.5767), Accuracy:83.84% (val:84.00%)\n",
      "Epoch [8/10], Step [19000], Loss: 0.6106 (val:0.6878), Accuracy:85.83% (val:76.67%)\n",
      "Epoch [8/10], Step [19100], Loss: 0.4728 (val:0.5977), Accuracy:87.50% (val:80.00%)\n",
      "Epoch [8/10], Step [19200], Loss: 0.4109 (val:0.6163), Accuracy:86.67% (val:83.33%)\n",
      "Epoch [8/10], Step [19300], Loss: 0.5244 (val:0.6377), Accuracy:85.00% (val:83.33%)\n",
      "Epoch [8/10], Step [19400], Loss: 0.6032 (val:0.9878), Accuracy:85.83% (val:73.33%)\n",
      "Epoch [8/10], Step [19500], Loss: 0.6252 (val:0.8183), Accuracy:81.67% (val:80.00%)\n",
      "Epoch [8/10], Step [19600], Loss: 0.3754 (val:0.8769), Accuracy:86.87% (val:80.00%)\n",
      "Epoch [8/10], Step [19700], Loss: 0.4955 (val:0.4141), Accuracy:82.50% (val:86.67%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [19800], Loss: 0.5849 (val:0.5834), Accuracy:87.50% (val:83.33%)\n",
      "Epoch [8/10], Step [19900], Loss: 0.5310 (val:0.7701), Accuracy:84.17% (val:80.00%)\n",
      "Epoch [8/10], Step [20000], Loss: 0.6412 (val:0.2697), Accuracy:81.67% (val:96.67%)\n",
      "Epoch [8/10], Step [20100], Loss: 0.7411 (val:0.5220), Accuracy:70.83% (val:86.67%)\n",
      "Epoch [8/10], Step [20200], Loss: 0.4695 (val:0.9279), Accuracy:84.17% (val:80.00%)\n",
      "Epoch [8/10], Step [20300], Loss: 0.6115 (val:0.4987), Accuracy:80.81% (val:84.00%)\n",
      "Epoch [8/10], Step [20400], Loss: 0.3987 (val:0.9854), Accuracy:84.17% (val:66.67%)\n",
      "Epoch [8/10], Step [20500], Loss: 0.6480 (val:0.6806), Accuracy:80.83% (val:70.00%)\n",
      "Epoch [8/10], Step [20600], Loss: 0.4807 (val:0.7320), Accuracy:88.33% (val:80.00%)\n",
      "Epoch [8/10], Step [20700], Loss: 0.5254 (val:0.3642), Accuracy:86.67% (val:86.67%)\n",
      "Epoch [8/10], Step [20800], Loss: 0.7985 (val:0.6225), Accuracy:78.33% (val:76.67%)\n",
      "Epoch [8/10], Step [20900], Loss: 0.4825 (val:0.2673), Accuracy:86.67% (val:93.33%)\n",
      "Epoch [8/10], Step [21000], Loss: 0.5789 (val:0.6935), Accuracy:82.83% (val:80.00%)\n",
      "Epoch [8/10], Step [21100], Loss: 0.6717 (val:0.8170), Accuracy:74.17% (val:83.33%)\n",
      "Epoch [8/10], Step [21200], Loss: 0.5968 (val:1.1399), Accuracy:86.67% (val:70.00%)\n",
      "Epoch [8/10], Step [21300], Loss: 0.6230 (val:1.0363), Accuracy:80.83% (val:80.00%)\n",
      "Epoch [8/10], Step [21400], Loss: 0.6297 (val:0.6521), Accuracy:81.67% (val:86.67%)\n",
      "Epoch [8/10], Step [21500], Loss: 0.5407 (val:0.4710), Accuracy:85.00% (val:86.67%)\n",
      "Epoch [8/10], Step [21600], Loss: 0.7181 (val:0.5191), Accuracy:77.50% (val:83.33%)\n",
      "Epoch [8/10], Step [21700], Loss: 0.7095 (val:0.5107), Accuracy:78.79% (val:88.00%)\n",
      "Epoch [8/10], Step [21800], Loss: 0.6694 (val:0.4828), Accuracy:80.00% (val:90.00%)\n",
      "Epoch [8/10], Step [21900], Loss: 0.4868 (val:0.5328), Accuracy:85.00% (val:86.67%)\n",
      "Epoch [8/10], Step [22000], Loss: 0.7171 (val:0.4584), Accuracy:78.33% (val:83.33%)\n",
      "Epoch [8/10], Step [22100], Loss: 0.8538 (val:0.7653), Accuracy:77.50% (val:83.33%)\n",
      "Epoch [8/10], Step [22200], Loss: 0.4927 (val:0.4360), Accuracy:85.83% (val:90.00%)\n",
      "Epoch [8/10], Step [22300], Loss: 0.5207 (val:0.5163), Accuracy:85.83% (val:80.00%)\n",
      "Epoch [8/10], Step [22400], Loss: 0.5385 (val:0.4374), Accuracy:85.86% (val:88.00%)\n",
      "Epoch [8/10], Step [22500], Loss: 0.5674 (val:0.9139), Accuracy:83.33% (val:76.67%)\n",
      "Epoch [8/10], Step [22600], Loss: 0.5945 (val:0.4204), Accuracy:81.67% (val:93.33%)\n",
      "Epoch [8/10], Step [22700], Loss: 0.5363 (val:0.7355), Accuracy:85.83% (val:83.33%)\n",
      "Epoch [8/10], Step [22800], Loss: 0.7623 (val:0.9047), Accuracy:81.67% (val:86.67%)\n",
      "Epoch [8/10], Step [22900], Loss: 0.6058 (val:0.4697), Accuracy:82.50% (val:83.33%)\n",
      "Epoch [8/10], Step [23000], Loss: 0.5230 (val:0.8853), Accuracy:86.67% (val:80.00%)\n",
      "Epoch [8/10], Step [23100], Loss: 0.6272 (val:0.9006), Accuracy:80.81% (val:72.00%)\n",
      "Epoch [8/10], Step [23200], Loss: 0.6822 (val:0.4851), Accuracy:80.00% (val:83.33%)\n",
      "Epoch [8/10], Step [23300], Loss: 0.5083 (val:0.6468), Accuracy:84.17% (val:86.67%)\n",
      "Epoch [8/10], Step [23400], Loss: 0.5920 (val:1.0940), Accuracy:81.67% (val:70.00%)\n",
      "Epoch [8/10], Step [23500], Loss: 0.6199 (val:0.5731), Accuracy:86.67% (val:83.33%)\n",
      "Epoch [8/10], Step [23600], Loss: 0.7521 (val:0.5551), Accuracy:82.50% (val:83.33%)\n",
      "Epoch [8/10], Step [23700], Loss: 0.5546 (val:0.6121), Accuracy:85.83% (val:80.00%)\n",
      "Epoch [8/10], Step [23800], Loss: 0.4684 (val:0.9646), Accuracy:90.91% (val:72.00%)\n",
      "Epoch [8/10], Step [23900], Loss: 0.6049 (val:0.4350), Accuracy:85.00% (val:90.00%)\n",
      "Epoch [8/10], Step [24000], Loss: 0.6278 (val:0.7554), Accuracy:83.33% (val:83.33%)\n",
      "Epoch [8/10], Step [24100], Loss: 0.4555 (val:0.3014), Accuracy:90.83% (val:96.67%)\n",
      "Epoch [8/10], Step [24200], Loss: 0.4836 (val:1.2204), Accuracy:89.17% (val:76.67%)\n",
      "Epoch [8/10], Step [24300], Loss: 0.6981 (val:0.5128), Accuracy:79.17% (val:80.00%)\n",
      "Epoch [8/10], Step [24400], Loss: 0.4609 (val:0.5139), Accuracy:86.67% (val:83.33%)\n",
      "Epoch [8/10], Step [24500], Loss: 0.4663 (val:0.7100), Accuracy:87.88% (val:72.00%)\n",
      "Epoch [8/10], Step [24600], Loss: 0.5707 (val:0.4320), Accuracy:85.83% (val:83.33%)\n",
      "Epoch [8/10], Step [24700], Loss: 0.4985 (val:0.7648), Accuracy:86.67% (val:83.33%)\n",
      "Epoch [8/10], Step [24800], Loss: 0.7607 (val:0.3538), Accuracy:79.17% (val:93.33%)\n",
      "Epoch [8/10], Step [24900], Loss: 0.5603 (val:1.0374), Accuracy:82.50% (val:80.00%)\n",
      "Epoch [8/10], Step [25000], Loss: 0.3038 (val:0.8610), Accuracy:91.67% (val:73.33%)\n",
      "Epoch [8/10], Step [25100], Loss: 0.4735 (val:0.6828), Accuracy:84.17% (val:76.67%)\n",
      "Epoch [8/10], Step [25200], Loss: 0.5793 (val:0.6969), Accuracy:81.82% (val:88.00%)\n",
      "Epoch [8/10], Step [25300], Loss: 0.6056 (val:0.5418), Accuracy:85.00% (val:80.00%)\n",
      "Epoch [8/10], Step [25400], Loss: 0.6119 (val:0.7467), Accuracy:83.33% (val:80.00%)\n",
      "Epoch [8/10], Step [25500], Loss: 0.4797 (val:0.4477), Accuracy:84.17% (val:86.67%)\n",
      "Epoch [8/10], Step [25600], Loss: 0.7346 (val:0.5010), Accuracy:77.50% (val:86.67%)\n",
      "Epoch [8/10], Step [25700], Loss: 0.6152 (val:0.8087), Accuracy:83.33% (val:80.00%)\n",
      "Epoch [8/10], Step [25800], Loss: 0.6831 (val:1.3860), Accuracy:82.50% (val:60.00%)\n",
      "Epoch [8/10], Step [25900], Loss: 0.6873 (val:0.3726), Accuracy:81.82% (val:84.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: generator 'ImageLoader.__iter__' raised StopIteration\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [100], Loss: 0.6513 (val:0.4120), Accuracy:80.83% (val:86.67%)\n",
      "Epoch [9/10], Step [200], Loss: 0.6834 (val:0.8513), Accuracy:77.50% (val:83.33%)\n",
      "Epoch [9/10], Step [300], Loss: 0.5311 (val:0.7644), Accuracy:85.83% (val:76.67%)\n",
      "Epoch [9/10], Step [400], Loss: 0.8144 (val:0.6899), Accuracy:75.00% (val:76.67%)\n",
      "Epoch [9/10], Step [500], Loss: 0.4809 (val:0.4606), Accuracy:88.33% (val:83.33%)\n",
      "Epoch [9/10], Step [600], Loss: 0.4829 (val:0.2658), Accuracy:88.33% (val:96.67%)\n",
      "Epoch [9/10], Step [700], Loss: 0.6714 (val:0.5102), Accuracy:82.83% (val:84.00%)\n",
      "Epoch [9/10], Step [800], Loss: 0.7654 (val:0.8037), Accuracy:80.83% (val:80.00%)\n",
      "Epoch [9/10], Step [900], Loss: 0.7304 (val:0.7246), Accuracy:77.50% (val:76.67%)\n",
      "Epoch [9/10], Step [1000], Loss: 0.5343 (val:0.5367), Accuracy:81.67% (val:83.33%)\n",
      "Epoch [9/10], Step [1100], Loss: 0.6019 (val:1.0107), Accuracy:85.83% (val:66.67%)\n",
      "Epoch [9/10], Step [1200], Loss: 0.5153 (val:0.4977), Accuracy:85.83% (val:86.67%)\n",
      "Epoch [9/10], Step [1300], Loss: 0.4989 (val:0.4122), Accuracy:86.67% (val:83.33%)\n",
      "Epoch [9/10], Step [1400], Loss: 0.8367 (val:0.6612), Accuracy:71.72% (val:80.00%)\n",
      "Epoch [9/10], Step [1500], Loss: 0.6026 (val:0.3924), Accuracy:82.50% (val:90.00%)\n",
      "Epoch [9/10], Step [1600], Loss: 0.4810 (val:0.4176), Accuracy:85.00% (val:90.00%)\n",
      "Epoch [9/10], Step [1700], Loss: 0.6279 (val:0.5735), Accuracy:80.83% (val:80.00%)\n",
      "Epoch [9/10], Step [1800], Loss: 0.5794 (val:0.7234), Accuracy:85.83% (val:83.33%)\n",
      "Epoch [9/10], Step [1900], Loss: 0.6753 (val:0.6495), Accuracy:80.83% (val:83.33%)\n",
      "Epoch [9/10], Step [2000], Loss: 0.6133 (val:0.5790), Accuracy:83.33% (val:86.67%)\n",
      "Epoch [9/10], Step [2100], Loss: 0.5668 (val:0.7124), Accuracy:80.81% (val:84.00%)\n",
      "Epoch [9/10], Step [2200], Loss: 0.7481 (val:0.5589), Accuracy:77.50% (val:90.00%)\n",
      "Epoch [9/10], Step [2300], Loss: 0.6640 (val:0.8255), Accuracy:80.83% (val:76.67%)\n",
      "Epoch [9/10], Step [2400], Loss: 0.5072 (val:0.7775), Accuracy:85.83% (val:80.00%)\n",
      "Epoch [9/10], Step [2500], Loss: 0.6806 (val:0.4245), Accuracy:80.00% (val:83.33%)\n",
      "Epoch [9/10], Step [2600], Loss: 0.6418 (val:0.2303), Accuracy:85.00% (val:93.33%)\n",
      "Epoch [9/10], Step [2700], Loss: 0.6565 (val:0.2122), Accuracy:80.83% (val:86.67%)\n",
      "Epoch [9/10], Step [2800], Loss: 0.8590 (val:0.6037), Accuracy:76.77% (val:88.00%)\n",
      "Epoch [9/10], Step [2900], Loss: 0.5847 (val:0.7483), Accuracy:84.17% (val:83.33%)\n",
      "Epoch [9/10], Step [3000], Loss: 0.5429 (val:0.1526), Accuracy:85.00% (val:96.67%)\n",
      "Epoch [9/10], Step [3100], Loss: 0.7958 (val:0.6186), Accuracy:81.67% (val:76.67%)\n",
      "Epoch [9/10], Step [3200], Loss: 0.5492 (val:0.7860), Accuracy:86.67% (val:86.67%)\n",
      "Epoch [9/10], Step [3300], Loss: 0.4825 (val:0.4170), Accuracy:82.50% (val:83.33%)\n",
      "Epoch [9/10], Step [3400], Loss: 0.6446 (val:0.9283), Accuracy:83.33% (val:76.67%)\n",
      "Epoch [9/10], Step [3500], Loss: 0.3844 (val:0.3557), Accuracy:84.85% (val:92.00%)\n",
      "Epoch [9/10], Step [3600], Loss: 0.4227 (val:0.6293), Accuracy:92.50% (val:90.00%)\n",
      "Epoch [9/10], Step [3700], Loss: 0.7311 (val:0.7443), Accuracy:79.17% (val:86.67%)\n",
      "Epoch [9/10], Step [3800], Loss: 0.7853 (val:0.7749), Accuracy:78.33% (val:76.67%)\n",
      "Epoch [9/10], Step [3900], Loss: 0.5890 (val:0.4439), Accuracy:84.17% (val:90.00%)\n",
      "Epoch [9/10], Step [4000], Loss: 0.5144 (val:0.4782), Accuracy:86.67% (val:83.33%)\n",
      "Epoch [9/10], Step [4100], Loss: 0.3974 (val:0.3846), Accuracy:89.17% (val:86.67%)\n",
      "Epoch [9/10], Step [4200], Loss: 0.5932 (val:0.7648), Accuracy:82.83% (val:80.00%)\n",
      "Epoch [9/10], Step [4300], Loss: 0.6230 (val:0.5165), Accuracy:85.83% (val:86.67%)\n",
      "Epoch [9/10], Step [4400], Loss: 0.5630 (val:0.7870), Accuracy:81.67% (val:80.00%)\n",
      "Epoch [9/10], Step [4500], Loss: 0.6223 (val:0.4746), Accuracy:84.17% (val:86.67%)\n",
      "Epoch [9/10], Step [4600], Loss: 0.7087 (val:0.5988), Accuracy:85.00% (val:80.00%)\n",
      "Epoch [9/10], Step [4700], Loss: 0.7765 (val:0.3841), Accuracy:81.67% (val:86.67%)\n",
      "Epoch [9/10], Step [4800], Loss: 0.5854 (val:0.7352), Accuracy:86.67% (val:80.00%)\n",
      "Epoch [9/10], Step [4900], Loss: 0.5483 (val:0.4905), Accuracy:82.83% (val:84.00%)\n",
      "Epoch [9/10], Step [5000], Loss: 0.7911 (val:0.6152), Accuracy:84.17% (val:86.67%)\n",
      "Epoch [9/10], Step [5100], Loss: 0.6755 (val:1.1749), Accuracy:80.83% (val:73.33%)\n",
      "Epoch [9/10], Step [5200], Loss: 0.5335 (val:0.4124), Accuracy:85.00% (val:90.00%)\n",
      "Epoch [9/10], Step [5300], Loss: 0.4384 (val:0.3541), Accuracy:88.33% (val:86.67%)\n",
      "Epoch [9/10], Step [5400], Loss: 0.5722 (val:0.6663), Accuracy:82.50% (val:83.33%)\n",
      "Epoch [9/10], Step [5500], Loss: 0.7565 (val:0.4568), Accuracy:79.17% (val:86.67%)\n",
      "Epoch [9/10], Step [5600], Loss: 0.6671 (val:0.2523), Accuracy:83.84% (val:92.00%)\n",
      "Epoch [9/10], Step [5700], Loss: 0.4564 (val:0.3032), Accuracy:87.50% (val:93.33%)\n",
      "Epoch [9/10], Step [5800], Loss: 0.6329 (val:0.7740), Accuracy:80.83% (val:80.00%)\n",
      "Epoch [9/10], Step [5900], Loss: 0.4847 (val:0.6765), Accuracy:84.17% (val:80.00%)\n",
      "Epoch [9/10], Step [6000], Loss: 0.7053 (val:0.3830), Accuracy:79.17% (val:90.00%)\n",
      "Epoch [9/10], Step [6100], Loss: 0.6704 (val:0.3408), Accuracy:79.17% (val:90.00%)\n",
      "Epoch [9/10], Step [6200], Loss: 0.6391 (val:0.5816), Accuracy:81.67% (val:76.67%)\n",
      "Epoch [9/10], Step [6300], Loss: 0.5176 (val:0.9586), Accuracy:80.81% (val:72.00%)\n",
      "Epoch [9/10], Step [6400], Loss: 0.5396 (val:0.5398), Accuracy:85.00% (val:80.00%)\n",
      "Epoch [9/10], Step [6500], Loss: 0.5146 (val:0.8125), Accuracy:84.17% (val:80.00%)\n",
      "Epoch [9/10], Step [6600], Loss: 0.3953 (val:0.5274), Accuracy:90.00% (val:86.67%)\n",
      "Epoch [9/10], Step [6700], Loss: 0.4927 (val:0.7876), Accuracy:87.50% (val:76.67%)\n",
      "Epoch [9/10], Step [6800], Loss: 0.6629 (val:0.7112), Accuracy:83.33% (val:86.67%)\n",
      "Epoch [9/10], Step [6900], Loss: 0.5595 (val:0.3565), Accuracy:81.67% (val:90.00%)\n",
      "Epoch [9/10], Step [7000], Loss: 0.4747 (val:0.0516), Accuracy:88.89% (val:100.00%)\n",
      "Epoch [9/10], Step [7100], Loss: 0.8783 (val:0.8162), Accuracy:81.67% (val:83.33%)\n",
      "Epoch [9/10], Step [7200], Loss: 0.6343 (val:1.0502), Accuracy:81.67% (val:73.33%)\n",
      "Epoch [9/10], Step [7300], Loss: 0.6390 (val:0.5139), Accuracy:81.67% (val:90.00%)\n",
      "Epoch [9/10], Step [7400], Loss: 0.5722 (val:0.5781), Accuracy:83.33% (val:80.00%)\n",
      "Epoch [9/10], Step [7500], Loss: 0.6297 (val:0.6145), Accuracy:85.83% (val:76.67%)\n",
      "Epoch [9/10], Step [7600], Loss: 0.6238 (val:0.4320), Accuracy:85.00% (val:83.33%)\n",
      "Epoch [9/10], Step [7700], Loss: 0.5455 (val:0.8655), Accuracy:83.84% (val:84.00%)\n",
      "Epoch [9/10], Step [7800], Loss: 0.7234 (val:0.7669), Accuracy:80.83% (val:76.67%)\n",
      "Epoch [9/10], Step [7900], Loss: 0.4956 (val:0.6108), Accuracy:84.17% (val:90.00%)\n",
      "Epoch [9/10], Step [8000], Loss: 0.7010 (val:0.4117), Accuracy:82.50% (val:90.00%)\n",
      "Epoch [9/10], Step [8100], Loss: 0.4190 (val:0.4915), Accuracy:86.67% (val:86.67%)\n",
      "Epoch [9/10], Step [8200], Loss: 0.4614 (val:0.6102), Accuracy:87.50% (val:83.33%)\n",
      "Epoch [9/10], Step [8300], Loss: 0.4818 (val:0.2365), Accuracy:85.00% (val:96.67%)\n",
      "Epoch [9/10], Step [8400], Loss: 0.6387 (val:0.3859), Accuracy:84.85% (val:84.00%)\n",
      "Epoch [9/10], Step [8500], Loss: 0.6389 (val:0.6257), Accuracy:80.00% (val:90.00%)\n",
      "Epoch [9/10], Step [8600], Loss: 0.5476 (val:0.8416), Accuracy:86.67% (val:83.33%)\n",
      "Epoch [9/10], Step [8700], Loss: 0.5904 (val:0.5143), Accuracy:84.17% (val:90.00%)\n",
      "Epoch [9/10], Step [8800], Loss: 0.5944 (val:0.3597), Accuracy:85.00% (val:90.00%)\n",
      "Epoch [9/10], Step [8900], Loss: 0.5025 (val:0.4031), Accuracy:85.00% (val:80.00%)\n",
      "Epoch [9/10], Step [9000], Loss: 0.7139 (val:0.5603), Accuracy:75.83% (val:93.33%)\n",
      "Epoch [9/10], Step [9100], Loss: 0.5326 (val:0.4519), Accuracy:87.88% (val:92.00%)\n",
      "Epoch [9/10], Step [9200], Loss: 0.5828 (val:0.4794), Accuracy:85.83% (val:90.00%)\n",
      "Epoch [9/10], Step [9300], Loss: 0.6455 (val:0.4634), Accuracy:81.67% (val:86.67%)\n",
      "Epoch [9/10], Step [9400], Loss: 0.4978 (val:0.7405), Accuracy:86.67% (val:83.33%)\n",
      "Epoch [9/10], Step [9500], Loss: 0.5689 (val:0.4231), Accuracy:84.17% (val:86.67%)\n",
      "Epoch [9/10], Step [9600], Loss: 0.4929 (val:0.3973), Accuracy:85.00% (val:86.67%)\n",
      "Epoch [9/10], Step [9700], Loss: 0.4055 (val:0.7378), Accuracy:89.17% (val:80.00%)\n",
      "Epoch [9/10], Step [9800], Loss: 0.6017 (val:0.3800), Accuracy:81.82% (val:84.00%)\n",
      "Epoch [9/10], Step [9900], Loss: 0.5552 (val:0.6198), Accuracy:87.50% (val:86.67%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [10000], Loss: 0.5365 (val:0.5081), Accuracy:85.00% (val:90.00%)\n",
      "Epoch [9/10], Step [10100], Loss: 0.6240 (val:0.9193), Accuracy:82.50% (val:80.00%)\n",
      "Epoch [9/10], Step [10200], Loss: 0.7602 (val:0.8940), Accuracy:80.83% (val:76.67%)\n",
      "Epoch [9/10], Step [10300], Loss: 0.5421 (val:1.0450), Accuracy:86.67% (val:73.33%)\n",
      "Epoch [9/10], Step [10400], Loss: 0.7520 (val:0.5624), Accuracy:78.33% (val:80.00%)\n",
      "Epoch [9/10], Step [10500], Loss: 0.8674 (val:0.8053), Accuracy:81.82% (val:84.00%)\n",
      "Epoch [9/10], Step [10600], Loss: 0.6623 (val:0.6038), Accuracy:85.00% (val:86.67%)\n",
      "Epoch [9/10], Step [10700], Loss: 0.6725 (val:0.3862), Accuracy:79.17% (val:86.67%)\n",
      "Epoch [9/10], Step [10800], Loss: 0.5740 (val:0.5622), Accuracy:84.17% (val:80.00%)\n",
      "Epoch [9/10], Step [10900], Loss: 0.4752 (val:0.5547), Accuracy:85.00% (val:80.00%)\n",
      "Epoch [9/10], Step [11000], Loss: 0.5756 (val:0.7364), Accuracy:85.83% (val:83.33%)\n",
      "Epoch [9/10], Step [11100], Loss: 0.5093 (val:0.3091), Accuracy:85.00% (val:96.67%)\n",
      "Epoch [9/10], Step [11200], Loss: 0.5770 (val:0.8784), Accuracy:83.84% (val:68.00%)\n",
      "Epoch [9/10], Step [11300], Loss: 0.6093 (val:1.0021), Accuracy:80.83% (val:76.67%)\n",
      "Epoch [9/10], Step [11400], Loss: 0.5693 (val:0.3143), Accuracy:85.83% (val:86.67%)\n",
      "Epoch [9/10], Step [11500], Loss: 0.7124 (val:0.5480), Accuracy:82.50% (val:76.67%)\n",
      "Epoch [9/10], Step [11600], Loss: 0.6435 (val:0.5259), Accuracy:83.33% (val:76.67%)\n",
      "Epoch [9/10], Step [11700], Loss: 0.7098 (val:0.5205), Accuracy:82.50% (val:80.00%)\n",
      "Epoch [9/10], Step [11800], Loss: 0.8009 (val:1.0073), Accuracy:77.50% (val:70.00%)\n",
      "Epoch [9/10], Step [11900], Loss: 0.3600 (val:0.2787), Accuracy:89.90% (val:96.00%)\n",
      "Epoch [9/10], Step [12000], Loss: 0.7790 (val:0.7142), Accuracy:75.00% (val:73.33%)\n",
      "Epoch [9/10], Step [12100], Loss: 0.4174 (val:0.5187), Accuracy:87.50% (val:90.00%)\n",
      "Epoch [9/10], Step [12200], Loss: 0.6090 (val:0.3699), Accuracy:79.17% (val:90.00%)\n",
      "Epoch [9/10], Step [12300], Loss: 0.6516 (val:0.5761), Accuracy:80.00% (val:83.33%)\n",
      "Epoch [9/10], Step [12400], Loss: 0.5292 (val:0.6599), Accuracy:86.67% (val:80.00%)\n",
      "Epoch [9/10], Step [12500], Loss: 0.5752 (val:0.7230), Accuracy:85.00% (val:80.00%)\n",
      "Epoch [9/10], Step [12600], Loss: 0.6395 (val:0.6768), Accuracy:86.87% (val:72.00%)\n",
      "Epoch [9/10], Step [12700], Loss: 0.7540 (val:1.0090), Accuracy:79.17% (val:80.00%)\n",
      "Epoch [9/10], Step [12800], Loss: 0.4595 (val:0.4835), Accuracy:86.67% (val:86.67%)\n",
      "Epoch [9/10], Step [12900], Loss: 0.4689 (val:0.4806), Accuracy:85.83% (val:83.33%)\n",
      "Epoch [9/10], Step [13000], Loss: 0.4256 (val:0.1744), Accuracy:87.50% (val:100.00%)\n",
      "Epoch [9/10], Step [13100], Loss: 0.5672 (val:0.9356), Accuracy:85.83% (val:70.00%)\n",
      "Epoch [9/10], Step [13200], Loss: 0.5303 (val:0.1820), Accuracy:88.33% (val:96.67%)\n",
      "Epoch [9/10], Step [13300], Loss: 0.7677 (val:0.8188), Accuracy:80.81% (val:76.00%)\n",
      "Epoch [9/10], Step [13400], Loss: 0.5237 (val:0.7288), Accuracy:85.00% (val:80.00%)\n",
      "Epoch [9/10], Step [13500], Loss: 0.4489 (val:1.0954), Accuracy:87.50% (val:80.00%)\n",
      "Epoch [9/10], Step [13600], Loss: 0.7391 (val:0.3582), Accuracy:80.00% (val:86.67%)\n",
      "Epoch [9/10], Step [13700], Loss: 0.6630 (val:0.7279), Accuracy:83.33% (val:73.33%)\n",
      "Epoch [9/10], Step [13800], Loss: 0.4778 (val:0.5567), Accuracy:85.83% (val:83.33%)\n",
      "Epoch [9/10], Step [13900], Loss: 0.6360 (val:0.7696), Accuracy:86.67% (val:76.67%)\n",
      "Epoch [9/10], Step [14000], Loss: 0.4832 (val:1.0029), Accuracy:88.89% (val:68.00%)\n",
      "Epoch [9/10], Step [14100], Loss: 0.4968 (val:0.5228), Accuracy:83.33% (val:83.33%)\n",
      "Epoch [9/10], Step [14200], Loss: 0.5139 (val:0.3818), Accuracy:90.83% (val:90.00%)\n",
      "Epoch [9/10], Step [14300], Loss: 0.6101 (val:0.2646), Accuracy:82.50% (val:96.67%)\n",
      "Epoch [9/10], Step [14400], Loss: 0.6751 (val:0.8594), Accuracy:79.17% (val:76.67%)\n",
      "Epoch [9/10], Step [14500], Loss: 0.7272 (val:0.5476), Accuracy:81.67% (val:80.00%)\n",
      "Epoch [9/10], Step [14600], Loss: 0.7035 (val:0.8229), Accuracy:80.00% (val:73.33%)\n",
      "Epoch [9/10], Step [14700], Loss: 0.7299 (val:0.3897), Accuracy:80.81% (val:88.00%)\n",
      "Epoch [9/10], Step [14800], Loss: 0.6481 (val:0.8115), Accuracy:81.67% (val:80.00%)\n",
      "Epoch [9/10], Step [14900], Loss: 0.5145 (val:0.8467), Accuracy:90.00% (val:70.00%)\n",
      "Epoch [9/10], Step [15000], Loss: 0.6546 (val:0.7033), Accuracy:82.50% (val:73.33%)\n",
      "Epoch [9/10], Step [15100], Loss: 0.6318 (val:0.4315), Accuracy:82.50% (val:90.00%)\n",
      "Epoch [9/10], Step [15200], Loss: 0.6374 (val:0.8446), Accuracy:83.33% (val:86.67%)\n",
      "Epoch [9/10], Step [15300], Loss: 0.7131 (val:0.6499), Accuracy:78.33% (val:80.00%)\n",
      "Epoch [9/10], Step [15400], Loss: 0.7324 (val:0.3169), Accuracy:78.79% (val:92.00%)\n",
      "Epoch [9/10], Step [15500], Loss: 0.6245 (val:0.7847), Accuracy:83.33% (val:76.67%)\n",
      "Epoch [9/10], Step [15600], Loss: 0.5659 (val:0.8615), Accuracy:85.00% (val:83.33%)\n",
      "Epoch [9/10], Step [15700], Loss: 0.4909 (val:0.2468), Accuracy:85.00% (val:93.33%)\n",
      "Epoch [9/10], Step [15800], Loss: 0.5239 (val:0.7114), Accuracy:81.67% (val:83.33%)\n",
      "Epoch [9/10], Step [15900], Loss: 0.6261 (val:0.7321), Accuracy:82.50% (val:83.33%)\n",
      "Epoch [9/10], Step [16000], Loss: 0.4481 (val:0.2324), Accuracy:89.17% (val:96.67%)\n",
      "Epoch [9/10], Step [16100], Loss: 0.4857 (val:0.3235), Accuracy:89.90% (val:92.00%)\n",
      "Epoch [9/10], Step [16200], Loss: 0.5207 (val:0.7322), Accuracy:85.83% (val:73.33%)\n",
      "Epoch [9/10], Step [16300], Loss: 0.6052 (val:0.7926), Accuracy:80.83% (val:73.33%)\n",
      "Epoch [9/10], Step [16400], Loss: 0.6060 (val:0.3970), Accuracy:83.33% (val:93.33%)\n",
      "Epoch [9/10], Step [16500], Loss: 0.5885 (val:0.5121), Accuracy:83.33% (val:83.33%)\n",
      "Epoch [9/10], Step [16600], Loss: 0.4522 (val:0.9575), Accuracy:87.50% (val:76.67%)\n",
      "Epoch [9/10], Step [16700], Loss: 0.5366 (val:1.3577), Accuracy:85.83% (val:70.00%)\n",
      "Epoch [9/10], Step [16800], Loss: 0.4987 (val:0.5522), Accuracy:91.92% (val:80.00%)\n",
      "Epoch [9/10], Step [16900], Loss: 0.8032 (val:0.5252), Accuracy:82.50% (val:93.33%)\n",
      "Epoch [9/10], Step [17000], Loss: 0.6282 (val:0.7566), Accuracy:85.00% (val:76.67%)\n",
      "Epoch [9/10], Step [17100], Loss: 0.5960 (val:0.4838), Accuracy:87.50% (val:90.00%)\n",
      "Epoch [9/10], Step [17200], Loss: 0.6104 (val:0.3859), Accuracy:80.00% (val:90.00%)\n",
      "Epoch [9/10], Step [17300], Loss: 0.4281 (val:0.7457), Accuracy:90.00% (val:86.67%)\n",
      "Epoch [9/10], Step [17400], Loss: 0.2987 (val:0.3439), Accuracy:93.33% (val:90.00%)\n",
      "Epoch [9/10], Step [17500], Loss: 0.8040 (val:0.2963), Accuracy:82.83% (val:92.00%)\n",
      "Epoch [9/10], Step [17600], Loss: 0.7557 (val:0.4574), Accuracy:81.67% (val:90.00%)\n",
      "Epoch [9/10], Step [17700], Loss: 0.4372 (val:0.8762), Accuracy:88.33% (val:80.00%)\n",
      "Epoch [9/10], Step [17800], Loss: 0.6490 (val:0.4339), Accuracy:82.50% (val:90.00%)\n",
      "Epoch [9/10], Step [17900], Loss: 0.4424 (val:0.3919), Accuracy:85.00% (val:90.00%)\n",
      "Epoch [9/10], Step [18000], Loss: 0.5125 (val:0.7190), Accuracy:84.17% (val:86.67%)\n",
      "Epoch [9/10], Step [18100], Loss: 0.5246 (val:0.3584), Accuracy:85.00% (val:93.33%)\n",
      "Epoch [9/10], Step [18200], Loss: 0.6878 (val:0.2012), Accuracy:81.82% (val:96.00%)\n",
      "Epoch [9/10], Step [18300], Loss: 0.6351 (val:0.4248), Accuracy:82.50% (val:86.67%)\n",
      "Epoch [9/10], Step [18400], Loss: 0.7055 (val:0.4044), Accuracy:75.00% (val:80.00%)\n",
      "Epoch [9/10], Step [18500], Loss: 0.6411 (val:0.9444), Accuracy:81.67% (val:83.33%)\n",
      "Epoch [9/10], Step [18600], Loss: 0.6369 (val:0.4773), Accuracy:85.00% (val:86.67%)\n",
      "Epoch [9/10], Step [18700], Loss: 0.5751 (val:0.5765), Accuracy:86.67% (val:80.00%)\n",
      "Epoch [9/10], Step [18800], Loss: 0.5882 (val:0.2479), Accuracy:85.00% (val:96.67%)\n",
      "Epoch [9/10], Step [18900], Loss: 0.4724 (val:0.7445), Accuracy:87.88% (val:80.00%)\n",
      "Epoch [9/10], Step [19000], Loss: 0.6332 (val:0.7699), Accuracy:83.33% (val:83.33%)\n",
      "Epoch [9/10], Step [19100], Loss: 0.4426 (val:1.0310), Accuracy:85.83% (val:76.67%)\n",
      "Epoch [9/10], Step [19200], Loss: 0.3995 (val:0.4429), Accuracy:86.67% (val:93.33%)\n",
      "Epoch [9/10], Step [19300], Loss: 0.5945 (val:0.8703), Accuracy:82.50% (val:73.33%)\n",
      "Epoch [9/10], Step [19400], Loss: 0.3870 (val:0.4798), Accuracy:90.00% (val:86.67%)\n",
      "Epoch [9/10], Step [19500], Loss: 0.6062 (val:0.5879), Accuracy:85.00% (val:80.00%)\n",
      "Epoch [9/10], Step [19600], Loss: 0.4956 (val:0.3643), Accuracy:88.89% (val:84.00%)\n",
      "Epoch [9/10], Step [19700], Loss: 0.5163 (val:0.6023), Accuracy:83.33% (val:76.67%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [19800], Loss: 0.6637 (val:0.7079), Accuracy:80.83% (val:76.67%)\n",
      "Epoch [9/10], Step [19900], Loss: 0.5706 (val:0.3476), Accuracy:84.17% (val:86.67%)\n",
      "Epoch [9/10], Step [20000], Loss: 0.4901 (val:0.3818), Accuracy:85.00% (val:93.33%)\n",
      "Epoch [9/10], Step [20100], Loss: 0.5337 (val:0.5178), Accuracy:85.00% (val:90.00%)\n",
      "Epoch [9/10], Step [20200], Loss: 0.4874 (val:0.5620), Accuracy:81.67% (val:86.67%)\n",
      "Epoch [9/10], Step [20300], Loss: 0.6026 (val:0.1376), Accuracy:84.85% (val:100.00%)\n",
      "Epoch [9/10], Step [20400], Loss: 0.5319 (val:0.5077), Accuracy:83.33% (val:83.33%)\n",
      "Epoch [9/10], Step [20500], Loss: 0.7254 (val:0.7736), Accuracy:82.50% (val:73.33%)\n",
      "Epoch [9/10], Step [20600], Loss: 0.4325 (val:0.6886), Accuracy:88.33% (val:76.67%)\n",
      "Epoch [9/10], Step [20700], Loss: 0.7302 (val:0.4967), Accuracy:82.50% (val:86.67%)\n",
      "Epoch [9/10], Step [20800], Loss: 0.6175 (val:0.4715), Accuracy:82.50% (val:83.33%)\n",
      "Epoch [9/10], Step [20900], Loss: 0.6576 (val:0.6592), Accuracy:85.00% (val:83.33%)\n",
      "Epoch [9/10], Step [21000], Loss: 0.6793 (val:0.2943), Accuracy:81.82% (val:92.00%)\n",
      "Epoch [9/10], Step [21100], Loss: 0.6344 (val:0.7402), Accuracy:81.67% (val:80.00%)\n",
      "Epoch [9/10], Step [21200], Loss: 0.7833 (val:0.6259), Accuracy:79.17% (val:76.67%)\n",
      "Epoch [9/10], Step [21300], Loss: 0.6592 (val:0.4625), Accuracy:80.83% (val:90.00%)\n",
      "Epoch [9/10], Step [21400], Loss: 0.7613 (val:0.6779), Accuracy:81.67% (val:80.00%)\n",
      "Epoch [9/10], Step [21500], Loss: 0.6398 (val:0.7271), Accuracy:85.00% (val:83.33%)\n",
      "Epoch [9/10], Step [21600], Loss: 0.5383 (val:0.4272), Accuracy:83.33% (val:90.00%)\n",
      "Epoch [9/10], Step [21700], Loss: 0.6180 (val:0.8162), Accuracy:81.82% (val:84.00%)\n",
      "Epoch [9/10], Step [21800], Loss: 0.6752 (val:0.5547), Accuracy:81.67% (val:83.33%)\n",
      "Epoch [9/10], Step [21900], Loss: 0.5680 (val:0.5074), Accuracy:80.83% (val:83.33%)\n",
      "Epoch [9/10], Step [22000], Loss: 0.4921 (val:0.4068), Accuracy:84.17% (val:83.33%)\n",
      "Epoch [9/10], Step [22100], Loss: 0.5734 (val:0.3660), Accuracy:82.50% (val:93.33%)\n",
      "Epoch [9/10], Step [22200], Loss: 0.3578 (val:0.5913), Accuracy:90.00% (val:80.00%)\n",
      "Epoch [9/10], Step [22300], Loss: 0.5312 (val:0.7288), Accuracy:86.67% (val:73.33%)\n",
      "Epoch [9/10], Step [22400], Loss: 0.5549 (val:0.3644), Accuracy:82.83% (val:92.00%)\n",
      "Epoch [9/10], Step [22500], Loss: 0.7011 (val:0.6998), Accuracy:76.67% (val:83.33%)\n",
      "Epoch [9/10], Step [22600], Loss: 0.4600 (val:0.6493), Accuracy:85.00% (val:80.00%)\n",
      "Epoch [9/10], Step [22700], Loss: 0.6755 (val:0.9407), Accuracy:81.67% (val:76.67%)\n",
      "Epoch [9/10], Step [22800], Loss: 0.5663 (val:0.4522), Accuracy:84.17% (val:86.67%)\n",
      "Epoch [9/10], Step [22900], Loss: 0.6410 (val:0.9355), Accuracy:82.50% (val:73.33%)\n",
      "Epoch [9/10], Step [23000], Loss: 0.5407 (val:0.6621), Accuracy:85.00% (val:73.33%)\n",
      "Epoch [9/10], Step [23100], Loss: 0.5416 (val:0.8306), Accuracy:84.85% (val:84.00%)\n",
      "Epoch [9/10], Step [23200], Loss: 0.4836 (val:0.3241), Accuracy:85.83% (val:83.33%)\n",
      "Epoch [9/10], Step [23300], Loss: 0.6486 (val:0.3001), Accuracy:82.50% (val:83.33%)\n",
      "Epoch [9/10], Step [23400], Loss: 0.7960 (val:0.5003), Accuracy:80.00% (val:86.67%)\n",
      "Epoch [9/10], Step [23500], Loss: 0.6348 (val:0.3383), Accuracy:80.83% (val:90.00%)\n",
      "Epoch [9/10], Step [23600], Loss: 0.5599 (val:0.8207), Accuracy:82.50% (val:73.33%)\n",
      "Epoch [9/10], Step [23700], Loss: 0.6468 (val:0.5541), Accuracy:85.00% (val:83.33%)\n",
      "Epoch [9/10], Step [23800], Loss: 0.5551 (val:1.0064), Accuracy:86.87% (val:76.00%)\n",
      "Epoch [9/10], Step [23900], Loss: 0.5052 (val:0.4871), Accuracy:88.33% (val:86.67%)\n",
      "Epoch [9/10], Step [24000], Loss: 0.6610 (val:0.4453), Accuracy:80.83% (val:90.00%)\n",
      "Epoch [9/10], Step [24100], Loss: 0.7164 (val:0.3553), Accuracy:80.00% (val:86.67%)\n",
      "Epoch [9/10], Step [24200], Loss: 0.6656 (val:0.5249), Accuracy:82.50% (val:86.67%)\n",
      "Epoch [9/10], Step [24300], Loss: 0.5431 (val:0.4787), Accuracy:84.17% (val:86.67%)\n",
      "Epoch [9/10], Step [24400], Loss: 0.6318 (val:0.6999), Accuracy:85.00% (val:73.33%)\n",
      "Epoch [9/10], Step [24500], Loss: 0.5515 (val:0.6821), Accuracy:84.85% (val:84.00%)\n",
      "Epoch [9/10], Step [24600], Loss: 0.5863 (val:0.4009), Accuracy:82.50% (val:93.33%)\n",
      "Epoch [9/10], Step [24700], Loss: 0.3686 (val:0.8258), Accuracy:89.17% (val:73.33%)\n",
      "Epoch [9/10], Step [24800], Loss: 0.5291 (val:0.6233), Accuracy:86.67% (val:86.67%)\n",
      "Epoch [9/10], Step [24900], Loss: 0.3249 (val:0.4052), Accuracy:92.50% (val:93.33%)\n",
      "Epoch [9/10], Step [25000], Loss: 0.5604 (val:0.3594), Accuracy:82.50% (val:93.33%)\n",
      "Epoch [9/10], Step [25100], Loss: 0.6966 (val:0.4651), Accuracy:77.50% (val:86.67%)\n",
      "Epoch [9/10], Step [25200], Loss: 0.9594 (val:0.3793), Accuracy:76.77% (val:88.00%)\n",
      "Epoch [9/10], Step [25300], Loss: 0.6785 (val:0.6468), Accuracy:80.83% (val:83.33%)\n",
      "Epoch [9/10], Step [25400], Loss: 0.5872 (val:0.4906), Accuracy:82.50% (val:93.33%)\n",
      "Epoch [9/10], Step [25500], Loss: 0.7850 (val:0.5521), Accuracy:77.50% (val:86.67%)\n",
      "Epoch [9/10], Step [25600], Loss: 0.5009 (val:0.8118), Accuracy:85.83% (val:73.33%)\n",
      "Epoch [9/10], Step [25700], Loss: 0.4664 (val:0.1769), Accuracy:84.17% (val:90.00%)\n",
      "Epoch [9/10], Step [25800], Loss: 0.7312 (val:0.3919), Accuracy:79.17% (val:86.67%)\n",
      "Epoch [9/10], Step [25900], Loss: 0.4697 (val:0.7875), Accuracy:86.87% (val:84.00%)\n",
      "Epoch [10/10], Step [100], Loss: 0.5113 (val:0.7533), Accuracy:85.83% (val:80.00%)\n",
      "Epoch [10/10], Step [200], Loss: 0.4713 (val:0.8067), Accuracy:88.33% (val:73.33%)\n",
      "Epoch [10/10], Step [300], Loss: 0.4698 (val:0.4844), Accuracy:88.33% (val:83.33%)\n",
      "Epoch [10/10], Step [400], Loss: 0.5605 (val:0.9229), Accuracy:81.67% (val:76.67%)\n",
      "Epoch [10/10], Step [500], Loss: 0.6547 (val:0.9089), Accuracy:81.67% (val:73.33%)\n",
      "Epoch [10/10], Step [600], Loss: 0.6137 (val:1.1807), Accuracy:81.67% (val:70.00%)\n",
      "Epoch [10/10], Step [700], Loss: 0.7039 (val:0.7934), Accuracy:79.80% (val:72.00%)\n",
      "Epoch [10/10], Step [800], Loss: 0.6430 (val:0.5639), Accuracy:80.83% (val:83.33%)\n",
      "Epoch [10/10], Step [900], Loss: 0.5741 (val:0.3073), Accuracy:83.33% (val:93.33%)\n",
      "Epoch [10/10], Step [1000], Loss: 0.5179 (val:0.2731), Accuracy:85.83% (val:90.00%)\n",
      "Epoch [10/10], Step [1100], Loss: 0.6263 (val:0.4859), Accuracy:84.17% (val:90.00%)\n",
      "Epoch [10/10], Step [1200], Loss: 0.5834 (val:0.1555), Accuracy:82.50% (val:96.67%)\n",
      "Epoch [10/10], Step [1300], Loss: 0.7268 (val:0.4533), Accuracy:77.50% (val:83.33%)\n",
      "Epoch [10/10], Step [1400], Loss: 0.6282 (val:0.6780), Accuracy:78.79% (val:80.00%)\n",
      "Epoch [10/10], Step [1500], Loss: 0.3112 (val:0.6218), Accuracy:90.00% (val:86.67%)\n",
      "Epoch [10/10], Step [1600], Loss: 0.5073 (val:0.8673), Accuracy:84.17% (val:73.33%)\n",
      "Epoch [10/10], Step [1700], Loss: 0.4723 (val:0.7132), Accuracy:85.83% (val:80.00%)\n",
      "Epoch [10/10], Step [1800], Loss: 0.6916 (val:0.2342), Accuracy:78.33% (val:96.67%)\n",
      "Epoch [10/10], Step [1900], Loss: 0.6524 (val:0.4414), Accuracy:81.67% (val:86.67%)\n",
      "Epoch [10/10], Step [2000], Loss: 0.6958 (val:0.1409), Accuracy:84.17% (val:100.00%)\n",
      "Epoch [10/10], Step [2100], Loss: 0.4615 (val:0.3681), Accuracy:85.86% (val:92.00%)\n",
      "Epoch [10/10], Step [2200], Loss: 0.6286 (val:0.5700), Accuracy:80.83% (val:83.33%)\n",
      "Epoch [10/10], Step [2300], Loss: 0.6887 (val:0.4888), Accuracy:80.83% (val:80.00%)\n",
      "Epoch [10/10], Step [2400], Loss: 0.5820 (val:0.6447), Accuracy:86.67% (val:86.67%)\n",
      "Epoch [10/10], Step [2500], Loss: 0.6246 (val:0.2969), Accuracy:80.83% (val:90.00%)\n",
      "Epoch [10/10], Step [2600], Loss: 0.6600 (val:0.1974), Accuracy:80.83% (val:96.67%)\n",
      "Epoch [10/10], Step [2700], Loss: 0.5176 (val:0.3746), Accuracy:88.33% (val:90.00%)\n",
      "Epoch [10/10], Step [2800], Loss: 0.7020 (val:0.3915), Accuracy:81.82% (val:80.00%)\n",
      "Epoch [10/10], Step [2900], Loss: 0.4271 (val:0.5527), Accuracy:88.33% (val:86.67%)\n",
      "Epoch [10/10], Step [3000], Loss: 0.5351 (val:0.2850), Accuracy:84.17% (val:90.00%)\n",
      "Epoch [10/10], Step [3100], Loss: 0.8284 (val:0.5653), Accuracy:78.33% (val:83.33%)\n",
      "Epoch [10/10], Step [3200], Loss: 0.5186 (val:0.4103), Accuracy:84.17% (val:83.33%)\n",
      "Epoch [10/10], Step [3300], Loss: 0.5882 (val:0.6241), Accuracy:83.33% (val:80.00%)\n",
      "Epoch [10/10], Step [3400], Loss: 0.5576 (val:0.3751), Accuracy:85.00% (val:90.00%)\n",
      "Epoch [10/10], Step [3500], Loss: 0.5011 (val:0.7774), Accuracy:83.84% (val:80.00%)\n",
      "Epoch [10/10], Step [3600], Loss: 0.6223 (val:0.7890), Accuracy:80.00% (val:70.00%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step [3700], Loss: 0.4884 (val:0.7345), Accuracy:87.50% (val:80.00%)\n",
      "Epoch [10/10], Step [3800], Loss: 0.6277 (val:0.6184), Accuracy:84.17% (val:80.00%)\n",
      "Epoch [10/10], Step [3900], Loss: 0.5720 (val:0.5332), Accuracy:85.83% (val:90.00%)\n",
      "Epoch [10/10], Step [4000], Loss: 0.6923 (val:0.4480), Accuracy:79.17% (val:86.67%)\n",
      "Epoch [10/10], Step [4100], Loss: 0.3452 (val:0.6180), Accuracy:88.33% (val:80.00%)\n",
      "Epoch [10/10], Step [4200], Loss: 0.5539 (val:1.3548), Accuracy:84.85% (val:68.00%)\n",
      "Epoch [10/10], Step [4300], Loss: 0.6302 (val:0.5206), Accuracy:82.50% (val:86.67%)\n",
      "Epoch [10/10], Step [4400], Loss: 0.4533 (val:0.8822), Accuracy:85.83% (val:73.33%)\n",
      "Epoch [10/10], Step [4500], Loss: 0.4326 (val:0.4237), Accuracy:90.83% (val:86.67%)\n",
      "Epoch [10/10], Step [4600], Loss: 0.7257 (val:0.9683), Accuracy:80.83% (val:76.67%)\n",
      "Epoch [10/10], Step [4700], Loss: 0.6163 (val:0.4288), Accuracy:83.33% (val:86.67%)\n",
      "Epoch [10/10], Step [4800], Loss: 0.6100 (val:0.6157), Accuracy:83.33% (val:83.33%)\n",
      "Epoch [10/10], Step [4900], Loss: 0.5499 (val:0.1038), Accuracy:79.80% (val:100.00%)\n",
      "Epoch [10/10], Step [5000], Loss: 0.7536 (val:0.6673), Accuracy:79.17% (val:86.67%)\n",
      "Epoch [10/10], Step [5100], Loss: 0.4953 (val:0.7974), Accuracy:84.17% (val:80.00%)\n",
      "Epoch [10/10], Step [5200], Loss: 0.6733 (val:0.7501), Accuracy:82.50% (val:80.00%)\n",
      "Epoch [10/10], Step [5300], Loss: 0.5889 (val:0.2409), Accuracy:85.83% (val:93.33%)\n",
      "Epoch [10/10], Step [5400], Loss: 0.4548 (val:0.5582), Accuracy:88.33% (val:83.33%)\n",
      "Epoch [10/10], Step [5500], Loss: 0.6341 (val:0.6951), Accuracy:84.17% (val:80.00%)\n",
      "Epoch [10/10], Step [5600], Loss: 0.5788 (val:0.8428), Accuracy:85.86% (val:80.00%)\n",
      "Epoch [10/10], Step [5700], Loss: 0.4608 (val:0.7079), Accuracy:88.33% (val:86.67%)\n",
      "Epoch [10/10], Step [5800], Loss: 0.6414 (val:0.6346), Accuracy:83.33% (val:76.67%)\n",
      "Epoch [10/10], Step [5900], Loss: 0.6255 (val:1.0298), Accuracy:84.17% (val:73.33%)\n",
      "Epoch [10/10], Step [6000], Loss: 0.4972 (val:0.1620), Accuracy:90.83% (val:96.67%)\n",
      "Epoch [10/10], Step [6100], Loss: 0.4848 (val:0.5134), Accuracy:84.17% (val:83.33%)\n",
      "Epoch [10/10], Step [6200], Loss: 0.5495 (val:0.6653), Accuracy:85.83% (val:76.67%)\n",
      "Epoch [10/10], Step [6300], Loss: 0.5760 (val:0.4213), Accuracy:83.84% (val:84.00%)\n",
      "Epoch [10/10], Step [6400], Loss: 0.6051 (val:0.4983), Accuracy:82.50% (val:80.00%)\n",
      "Epoch [10/10], Step [6500], Loss: 0.4016 (val:0.5318), Accuracy:90.83% (val:83.33%)\n",
      "Epoch [10/10], Step [6600], Loss: 0.6604 (val:0.2915), Accuracy:84.17% (val:96.67%)\n",
      "Epoch [10/10], Step [6700], Loss: 0.4306 (val:0.6305), Accuracy:87.50% (val:83.33%)\n",
      "Epoch [10/10], Step [6800], Loss: 0.5612 (val:0.4741), Accuracy:87.50% (val:90.00%)\n",
      "Epoch [10/10], Step [6900], Loss: 0.3994 (val:0.7983), Accuracy:90.00% (val:70.00%)\n",
      "Epoch [10/10], Step [7000], Loss: 0.5495 (val:0.6846), Accuracy:77.78% (val:84.00%)\n",
      "Epoch [10/10], Step [7100], Loss: 0.5822 (val:0.8678), Accuracy:80.83% (val:70.00%)\n",
      "Epoch [10/10], Step [7200], Loss: 0.4570 (val:0.5487), Accuracy:85.00% (val:86.67%)\n",
      "Epoch [10/10], Step [7300], Loss: 0.6400 (val:0.3576), Accuracy:85.00% (val:90.00%)\n",
      "Epoch [10/10], Step [7400], Loss: 0.5314 (val:0.4829), Accuracy:81.67% (val:86.67%)\n",
      "Epoch [10/10], Step [7500], Loss: 0.6065 (val:0.4501), Accuracy:81.67% (val:90.00%)\n",
      "Epoch [10/10], Step [7600], Loss: 0.5692 (val:0.6151), Accuracy:83.33% (val:83.33%)\n",
      "Epoch [10/10], Step [7700], Loss: 0.6711 (val:0.4409), Accuracy:82.83% (val:88.00%)\n",
      "Epoch [10/10], Step [7800], Loss: 0.5974 (val:0.5945), Accuracy:81.67% (val:76.67%)\n",
      "Epoch [10/10], Step [7900], Loss: 0.6763 (val:0.3990), Accuracy:81.67% (val:86.67%)\n",
      "Epoch [10/10], Step [8000], Loss: 0.7290 (val:0.9693), Accuracy:80.83% (val:73.33%)\n",
      "Epoch [10/10], Step [8100], Loss: 0.4961 (val:0.7400), Accuracy:86.67% (val:70.00%)\n",
      "Epoch [10/10], Step [8200], Loss: 0.7118 (val:0.3177), Accuracy:82.50% (val:90.00%)\n",
      "Epoch [10/10], Step [8300], Loss: 0.6204 (val:0.6445), Accuracy:85.00% (val:90.00%)\n",
      "Epoch [10/10], Step [8400], Loss: 0.6096 (val:0.7492), Accuracy:85.86% (val:80.00%)\n",
      "Epoch [10/10], Step [8500], Loss: 0.4780 (val:0.3307), Accuracy:85.00% (val:90.00%)\n",
      "Epoch [10/10], Step [8600], Loss: 0.5734 (val:0.3537), Accuracy:82.50% (val:93.33%)\n",
      "Epoch [10/10], Step [8700], Loss: 0.5862 (val:0.7687), Accuracy:82.50% (val:76.67%)\n",
      "Epoch [10/10], Step [8800], Loss: 0.8711 (val:0.4618), Accuracy:80.00% (val:83.33%)\n",
      "Epoch [10/10], Step [8900], Loss: 0.5024 (val:0.9417), Accuracy:85.00% (val:70.00%)\n",
      "Epoch [10/10], Step [9000], Loss: 0.3712 (val:0.2140), Accuracy:88.33% (val:93.33%)\n",
      "Epoch [10/10], Step [9100], Loss: 0.7573 (val:0.8664), Accuracy:79.80% (val:80.00%)\n",
      "Epoch [10/10], Step [9200], Loss: 0.3289 (val:0.4996), Accuracy:91.67% (val:80.00%)\n",
      "Epoch [10/10], Step [9300], Loss: 0.6299 (val:0.6756), Accuracy:80.00% (val:83.33%)\n",
      "Epoch [10/10], Step [9400], Loss: 0.7080 (val:0.5892), Accuracy:79.17% (val:86.67%)\n",
      "Epoch [10/10], Step [9500], Loss: 0.5698 (val:0.6034), Accuracy:84.17% (val:80.00%)\n",
      "Epoch [10/10], Step [9600], Loss: 0.5686 (val:0.8720), Accuracy:83.33% (val:76.67%)\n",
      "Epoch [10/10], Step [9700], Loss: 0.6904 (val:0.4700), Accuracy:83.33% (val:83.33%)\n",
      "Epoch [10/10], Step [9800], Loss: 0.5917 (val:0.5875), Accuracy:83.84% (val:88.00%)\n",
      "Epoch [10/10], Step [9900], Loss: 0.5735 (val:0.6924), Accuracy:84.17% (val:80.00%)\n",
      "Epoch [10/10], Step [10000], Loss: 0.7256 (val:0.5778), Accuracy:77.50% (val:80.00%)\n",
      "Epoch [10/10], Step [10100], Loss: 0.6278 (val:0.6823), Accuracy:82.50% (val:83.33%)\n",
      "Epoch [10/10], Step [10200], Loss: 0.5785 (val:0.6448), Accuracy:82.50% (val:83.33%)\n",
      "Epoch [10/10], Step [10300], Loss: 0.7921 (val:0.4988), Accuracy:77.50% (val:83.33%)\n",
      "Epoch [10/10], Step [10400], Loss: 0.5834 (val:0.7223), Accuracy:83.33% (val:80.00%)\n",
      "Epoch [10/10], Step [10500], Loss: 0.8017 (val:0.6945), Accuracy:77.78% (val:76.00%)\n",
      "Epoch [10/10], Step [10600], Loss: 0.5133 (val:0.3805), Accuracy:85.00% (val:90.00%)\n",
      "Epoch [10/10], Step [10700], Loss: 0.5987 (val:0.6450), Accuracy:81.67% (val:83.33%)\n",
      "Epoch [10/10], Step [10800], Loss: 0.6049 (val:0.5429), Accuracy:82.50% (val:86.67%)\n",
      "Epoch [10/10], Step [10900], Loss: 0.7008 (val:0.6751), Accuracy:80.83% (val:73.33%)\n",
      "Epoch [10/10], Step [11000], Loss: 0.7039 (val:0.3670), Accuracy:82.50% (val:86.67%)\n",
      "Epoch [10/10], Step [11100], Loss: 0.5588 (val:0.3619), Accuracy:85.00% (val:86.67%)\n",
      "Epoch [10/10], Step [11200], Loss: 0.5463 (val:0.8470), Accuracy:84.85% (val:84.00%)\n",
      "Epoch [10/10], Step [11300], Loss: 0.8585 (val:0.5191), Accuracy:79.17% (val:80.00%)\n",
      "Epoch [10/10], Step [11400], Loss: 0.5024 (val:0.5712), Accuracy:88.33% (val:76.67%)\n",
      "Epoch [10/10], Step [11500], Loss: 0.3692 (val:0.5856), Accuracy:89.17% (val:80.00%)\n",
      "Epoch [10/10], Step [11600], Loss: 0.5104 (val:0.4208), Accuracy:85.83% (val:90.00%)\n",
      "Epoch [10/10], Step [11700], Loss: 0.8866 (val:0.2988), Accuracy:75.00% (val:86.67%)\n",
      "Epoch [10/10], Step [11800], Loss: 0.5113 (val:0.4821), Accuracy:84.17% (val:90.00%)\n",
      "Epoch [10/10], Step [11900], Loss: 0.4652 (val:1.0170), Accuracy:87.88% (val:68.00%)\n",
      "Epoch [10/10], Step [12000], Loss: 0.3875 (val:0.9313), Accuracy:88.33% (val:73.33%)\n",
      "Epoch [10/10], Step [12100], Loss: 0.5728 (val:0.5902), Accuracy:85.83% (val:83.33%)\n",
      "Epoch [10/10], Step [12200], Loss: 0.5273 (val:0.3055), Accuracy:85.00% (val:90.00%)\n",
      "Epoch [10/10], Step [12300], Loss: 0.6394 (val:0.6350), Accuracy:80.00% (val:76.67%)\n",
      "Epoch [10/10], Step [12400], Loss: 0.5475 (val:0.3135), Accuracy:83.33% (val:90.00%)\n",
      "Epoch [10/10], Step [12500], Loss: 0.5706 (val:0.3296), Accuracy:81.67% (val:90.00%)\n",
      "Epoch [10/10], Step [12600], Loss: 0.4879 (val:0.7729), Accuracy:84.85% (val:84.00%)\n",
      "Epoch [10/10], Step [12700], Loss: 0.7271 (val:0.9101), Accuracy:80.00% (val:80.00%)\n",
      "Epoch [10/10], Step [12800], Loss: 0.6244 (val:0.2664), Accuracy:85.00% (val:93.33%)\n",
      "Epoch [10/10], Step [12900], Loss: 0.4302 (val:0.6984), Accuracy:88.33% (val:86.67%)\n",
      "Epoch [10/10], Step [13000], Loss: 0.5309 (val:0.5665), Accuracy:85.00% (val:90.00%)\n",
      "Epoch [10/10], Step [13100], Loss: 0.6780 (val:0.4850), Accuracy:79.17% (val:86.67%)\n",
      "Epoch [10/10], Step [13200], Loss: 0.7340 (val:0.5939), Accuracy:77.50% (val:80.00%)\n",
      "Epoch [10/10], Step [13300], Loss: 0.6955 (val:0.9196), Accuracy:80.81% (val:80.00%)\n",
      "Epoch [10/10], Step [13400], Loss: 0.4744 (val:0.4443), Accuracy:88.33% (val:83.33%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step [13500], Loss: 0.8623 (val:0.3739), Accuracy:79.17% (val:86.67%)\n",
      "Epoch [10/10], Step [13600], Loss: 0.6775 (val:0.5078), Accuracy:79.17% (val:86.67%)\n",
      "Epoch [10/10], Step [13700], Loss: 0.6929 (val:0.4180), Accuracy:82.50% (val:86.67%)\n",
      "Epoch [10/10], Step [13800], Loss: 0.3900 (val:0.4926), Accuracy:90.83% (val:86.67%)\n",
      "Epoch [10/10], Step [13900], Loss: 0.8774 (val:0.8802), Accuracy:78.33% (val:73.33%)\n",
      "Epoch [10/10], Step [14000], Loss: 0.8299 (val:0.1802), Accuracy:75.76% (val:96.00%)\n",
      "Epoch [10/10], Step [14100], Loss: 0.5358 (val:0.3963), Accuracy:83.33% (val:90.00%)\n",
      "Epoch [10/10], Step [14200], Loss: 0.5583 (val:0.9492), Accuracy:84.17% (val:80.00%)\n",
      "Epoch [10/10], Step [14300], Loss: 0.5945 (val:0.7459), Accuracy:83.33% (val:80.00%)\n",
      "Epoch [10/10], Step [14400], Loss: 0.6589 (val:0.6005), Accuracy:80.83% (val:83.33%)\n",
      "Epoch [10/10], Step [14500], Loss: 0.6837 (val:0.4394), Accuracy:82.50% (val:86.67%)\n",
      "Epoch [10/10], Step [14600], Loss: 0.6358 (val:0.4163), Accuracy:83.33% (val:83.33%)\n",
      "Epoch [10/10], Step [14700], Loss: 0.7204 (val:0.6702), Accuracy:83.84% (val:76.00%)\n",
      "Epoch [10/10], Step [14800], Loss: 0.7131 (val:1.3123), Accuracy:76.67% (val:60.00%)\n",
      "Epoch [10/10], Step [14900], Loss: 0.5161 (val:0.6685), Accuracy:85.83% (val:83.33%)\n",
      "Epoch [10/10], Step [15000], Loss: 0.4554 (val:0.7411), Accuracy:89.17% (val:76.67%)\n",
      "Epoch [10/10], Step [15100], Loss: 0.4547 (val:0.3751), Accuracy:86.67% (val:96.67%)\n",
      "Epoch [10/10], Step [15200], Loss: 0.8321 (val:0.2861), Accuracy:77.50% (val:93.33%)\n",
      "Epoch [10/10], Step [15300], Loss: 0.6010 (val:0.3615), Accuracy:84.17% (val:86.67%)\n",
      "Epoch [10/10], Step [15400], Loss: 0.6100 (val:0.3863), Accuracy:81.82% (val:88.00%)\n",
      "Epoch [10/10], Step [15500], Loss: 0.5941 (val:0.3464), Accuracy:85.83% (val:96.67%)\n",
      "Epoch [10/10], Step [15600], Loss: 0.4439 (val:0.4775), Accuracy:89.17% (val:83.33%)\n",
      "Epoch [10/10], Step [15700], Loss: 0.6228 (val:0.2685), Accuracy:84.17% (val:93.33%)\n",
      "Epoch [10/10], Step [15800], Loss: 0.6210 (val:0.3759), Accuracy:85.00% (val:86.67%)\n",
      "Epoch [10/10], Step [15900], Loss: 0.6017 (val:0.7838), Accuracy:81.67% (val:70.00%)\n",
      "Epoch [10/10], Step [16000], Loss: 0.5119 (val:0.2867), Accuracy:87.50% (val:90.00%)\n",
      "Epoch [10/10], Step [16100], Loss: 0.5603 (val:0.7240), Accuracy:82.83% (val:80.00%)\n",
      "Epoch [10/10], Step [16200], Loss: 0.5024 (val:0.6972), Accuracy:87.50% (val:80.00%)\n",
      "Epoch [10/10], Step [16300], Loss: 0.6053 (val:0.4542), Accuracy:85.83% (val:86.67%)\n",
      "Epoch [10/10], Step [16400], Loss: 0.6424 (val:0.3648), Accuracy:75.83% (val:93.33%)\n",
      "Epoch [10/10], Step [16500], Loss: 0.5842 (val:0.3222), Accuracy:83.33% (val:93.33%)\n",
      "Epoch [10/10], Step [16600], Loss: 0.6006 (val:0.8093), Accuracy:82.50% (val:73.33%)\n",
      "Epoch [10/10], Step [16700], Loss: 0.4763 (val:0.7202), Accuracy:84.17% (val:80.00%)\n",
      "Epoch [10/10], Step [16800], Loss: 0.5483 (val:0.2923), Accuracy:83.84% (val:88.00%)\n",
      "Epoch [10/10], Step [16900], Loss: 0.7431 (val:0.2415), Accuracy:78.33% (val:100.00%)\n",
      "Epoch [10/10], Step [17000], Loss: 0.4225 (val:0.6427), Accuracy:85.83% (val:86.67%)\n",
      "Epoch [10/10], Step [17100], Loss: 0.6529 (val:0.2474), Accuracy:81.67% (val:90.00%)\n",
      "Epoch [10/10], Step [17200], Loss: 0.6414 (val:0.3240), Accuracy:82.50% (val:90.00%)\n",
      "Epoch [10/10], Step [17300], Loss: 0.5953 (val:0.7427), Accuracy:82.50% (val:80.00%)\n",
      "Epoch [10/10], Step [17400], Loss: 0.5289 (val:0.3562), Accuracy:85.83% (val:90.00%)\n",
      "Epoch [10/10], Step [17500], Loss: 0.5035 (val:0.5765), Accuracy:82.83% (val:88.00%)\n",
      "Epoch [10/10], Step [17600], Loss: 0.7587 (val:0.3305), Accuracy:80.83% (val:90.00%)\n",
      "Epoch [10/10], Step [17700], Loss: 0.6957 (val:0.4930), Accuracy:80.83% (val:83.33%)\n",
      "Epoch [10/10], Step [17800], Loss: 0.4719 (val:0.4352), Accuracy:86.67% (val:83.33%)\n",
      "Epoch [10/10], Step [17900], Loss: 0.6234 (val:0.5893), Accuracy:79.17% (val:90.00%)\n",
      "Epoch [10/10], Step [18000], Loss: 0.5414 (val:0.2826), Accuracy:83.33% (val:93.33%)\n",
      "Epoch [10/10], Step [18100], Loss: 0.4921 (val:0.9852), Accuracy:85.83% (val:80.00%)\n",
      "Epoch [10/10], Step [18200], Loss: 0.5726 (val:0.6474), Accuracy:85.86% (val:88.00%)\n",
      "Epoch [10/10], Step [18300], Loss: 0.6095 (val:0.8349), Accuracy:86.67% (val:76.67%)\n",
      "Epoch [10/10], Step [18400], Loss: 0.6764 (val:0.4647), Accuracy:80.00% (val:86.67%)\n",
      "Epoch [10/10], Step [18500], Loss: 0.4330 (val:0.5870), Accuracy:87.50% (val:70.00%)\n",
      "Epoch [10/10], Step [18600], Loss: 0.5482 (val:0.5242), Accuracy:84.17% (val:86.67%)\n",
      "Epoch [10/10], Step [18700], Loss: 0.4956 (val:0.3553), Accuracy:84.17% (val:90.00%)\n",
      "Epoch [10/10], Step [18800], Loss: 0.6631 (val:1.1319), Accuracy:84.17% (val:76.67%)\n",
      "Epoch [10/10], Step [18900], Loss: 0.6388 (val:0.4532), Accuracy:81.82% (val:84.00%)\n",
      "Epoch [10/10], Step [19000], Loss: 0.5544 (val:0.7772), Accuracy:85.83% (val:83.33%)\n",
      "Epoch [10/10], Step [19100], Loss: 0.5389 (val:0.6133), Accuracy:85.00% (val:90.00%)\n",
      "Epoch [10/10], Step [19200], Loss: 0.6588 (val:0.5112), Accuracy:78.33% (val:83.33%)\n",
      "Epoch [10/10], Step [19300], Loss: 0.6265 (val:0.3577), Accuracy:82.50% (val:90.00%)\n",
      "Epoch [10/10], Step [19400], Loss: 0.7072 (val:0.7024), Accuracy:80.83% (val:76.67%)\n",
      "Epoch [10/10], Step [19500], Loss: 0.6799 (val:1.1052), Accuracy:84.17% (val:66.67%)\n",
      "Epoch [10/10], Step [19600], Loss: 0.6616 (val:0.5150), Accuracy:83.84% (val:84.00%)\n",
      "Epoch [10/10], Step [19700], Loss: 0.4511 (val:0.4094), Accuracy:85.00% (val:90.00%)\n",
      "Epoch [10/10], Step [19800], Loss: 0.5029 (val:0.9660), Accuracy:87.50% (val:73.33%)\n",
      "Epoch [10/10], Step [19900], Loss: 0.5650 (val:0.6745), Accuracy:82.50% (val:76.67%)\n",
      "Epoch [10/10], Step [20000], Loss: 0.4856 (val:0.3030), Accuracy:84.17% (val:90.00%)\n",
      "Epoch [10/10], Step [20100], Loss: 0.5333 (val:0.5435), Accuracy:82.50% (val:90.00%)\n",
      "Epoch [10/10], Step [20200], Loss: 0.5367 (val:1.2206), Accuracy:84.17% (val:70.00%)\n",
      "Epoch [10/10], Step [20300], Loss: 0.6674 (val:0.3052), Accuracy:82.83% (val:92.00%)\n",
      "Epoch [10/10], Step [20400], Loss: 0.4007 (val:0.5041), Accuracy:89.17% (val:86.67%)\n",
      "Epoch [10/10], Step [20500], Loss: 0.6977 (val:0.9858), Accuracy:81.67% (val:80.00%)\n",
      "Epoch [10/10], Step [20600], Loss: 0.6988 (val:0.4032), Accuracy:80.00% (val:93.33%)\n",
      "Epoch [10/10], Step [20700], Loss: 0.5076 (val:0.4387), Accuracy:82.50% (val:90.00%)\n",
      "Epoch [10/10], Step [20800], Loss: 0.5155 (val:0.7001), Accuracy:82.50% (val:86.67%)\n",
      "Epoch [10/10], Step [20900], Loss: 0.4125 (val:0.6136), Accuracy:90.00% (val:90.00%)\n",
      "Epoch [10/10], Step [21000], Loss: 0.4949 (val:0.7511), Accuracy:84.85% (val:76.00%)\n",
      "Epoch [10/10], Step [21100], Loss: 0.6251 (val:0.5738), Accuracy:83.33% (val:83.33%)\n",
      "Epoch [10/10], Step [21200], Loss: 0.5722 (val:0.7685), Accuracy:86.67% (val:80.00%)\n",
      "Epoch [10/10], Step [21300], Loss: 0.6800 (val:0.4090), Accuracy:80.83% (val:90.00%)\n",
      "Epoch [10/10], Step [21400], Loss: 0.5290 (val:0.4463), Accuracy:88.33% (val:93.33%)\n",
      "Epoch [10/10], Step [21500], Loss: 0.4782 (val:0.3101), Accuracy:84.17% (val:93.33%)\n",
      "Epoch [10/10], Step [21600], Loss: 0.6312 (val:0.8011), Accuracy:85.83% (val:73.33%)\n",
      "Epoch [10/10], Step [21700], Loss: 0.5803 (val:0.3003), Accuracy:85.86% (val:92.00%)\n",
      "Epoch [10/10], Step [21800], Loss: 0.4865 (val:0.2967), Accuracy:86.67% (val:93.33%)\n",
      "Epoch [10/10], Step [21900], Loss: 0.5131 (val:0.8812), Accuracy:83.33% (val:76.67%)\n",
      "Epoch [10/10], Step [22000], Loss: 0.5361 (val:0.8217), Accuracy:84.17% (val:86.67%)\n",
      "Epoch [10/10], Step [22100], Loss: 0.3359 (val:0.4678), Accuracy:93.33% (val:83.33%)\n",
      "Epoch [10/10], Step [22200], Loss: 0.6606 (val:0.3250), Accuracy:80.00% (val:86.67%)\n",
      "Epoch [10/10], Step [22300], Loss: 0.4777 (val:0.4508), Accuracy:88.33% (val:90.00%)\n",
      "Epoch [10/10], Step [22400], Loss: 0.5273 (val:0.6594), Accuracy:83.84% (val:80.00%)\n",
      "Epoch [10/10], Step [22500], Loss: 0.5713 (val:0.3370), Accuracy:84.17% (val:90.00%)\n",
      "Epoch [10/10], Step [22600], Loss: 0.4519 (val:0.4126), Accuracy:90.00% (val:86.67%)\n",
      "Epoch [10/10], Step [22700], Loss: 0.7676 (val:0.5052), Accuracy:80.00% (val:83.33%)\n",
      "Epoch [10/10], Step [22800], Loss: 0.6038 (val:0.4010), Accuracy:79.17% (val:86.67%)\n",
      "Epoch [10/10], Step [22900], Loss: 0.7612 (val:0.9034), Accuracy:78.33% (val:83.33%)\n",
      "Epoch [10/10], Step [23000], Loss: 0.6121 (val:0.5391), Accuracy:80.00% (val:83.33%)\n",
      "Epoch [10/10], Step [23100], Loss: 0.4553 (val:0.3619), Accuracy:83.84% (val:88.00%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step [23200], Loss: 0.4681 (val:0.3363), Accuracy:83.33% (val:90.00%)\n",
      "Epoch [10/10], Step [23300], Loss: 0.6428 (val:0.9159), Accuracy:81.67% (val:80.00%)\n",
      "Epoch [10/10], Step [23400], Loss: 0.8698 (val:0.7536), Accuracy:77.50% (val:83.33%)\n",
      "Epoch [10/10], Step [23500], Loss: 0.5386 (val:0.5438), Accuracy:84.17% (val:83.33%)\n",
      "Epoch [10/10], Step [23600], Loss: 0.4313 (val:1.1750), Accuracy:87.50% (val:66.67%)\n",
      "Epoch [10/10], Step [23700], Loss: 0.4358 (val:0.1575), Accuracy:89.17% (val:100.00%)\n",
      "Epoch [10/10], Step [23800], Loss: 0.6520 (val:0.7606), Accuracy:83.84% (val:84.00%)\n",
      "Epoch [10/10], Step [23900], Loss: 0.7529 (val:0.3911), Accuracy:77.50% (val:90.00%)\n",
      "Epoch [10/10], Step [24000], Loss: 0.5793 (val:0.5764), Accuracy:85.00% (val:80.00%)\n",
      "Epoch [10/10], Step [24100], Loss: 0.6044 (val:0.2576), Accuracy:83.33% (val:90.00%)\n",
      "Epoch [10/10], Step [24200], Loss: 0.5960 (val:1.2326), Accuracy:82.50% (val:73.33%)\n",
      "Epoch [10/10], Step [24300], Loss: 0.4689 (val:0.4333), Accuracy:85.83% (val:83.33%)\n",
      "Epoch [10/10], Step [24400], Loss: 0.4485 (val:0.6065), Accuracy:85.00% (val:86.67%)\n",
      "Epoch [10/10], Step [24500], Loss: 0.6089 (val:0.6710), Accuracy:81.82% (val:84.00%)\n",
      "Epoch [10/10], Step [24600], Loss: 0.6225 (val:0.4263), Accuracy:81.67% (val:83.33%)\n",
      "Epoch [10/10], Step [24700], Loss: 0.5870 (val:0.1436), Accuracy:84.17% (val:96.67%)\n",
      "Epoch [10/10], Step [24800], Loss: 0.7498 (val:0.8178), Accuracy:80.00% (val:76.67%)\n",
      "Epoch [10/10], Step [24900], Loss: 0.5805 (val:0.3820), Accuracy:83.33% (val:83.33%)\n",
      "Epoch [10/10], Step [25000], Loss: 0.6911 (val:0.1765), Accuracy:80.00% (val:93.33%)\n",
      "Epoch [10/10], Step [25100], Loss: 0.3878 (val:0.3602), Accuracy:85.83% (val:90.00%)\n",
      "Epoch [10/10], Step [25200], Loss: 0.6836 (val:0.6896), Accuracy:81.82% (val:76.00%)\n",
      "Epoch [10/10], Step [25300], Loss: 0.6331 (val:0.4474), Accuracy:81.67% (val:90.00%)\n",
      "Epoch [10/10], Step [25400], Loss: 0.8221 (val:1.1255), Accuracy:80.83% (val:76.67%)\n",
      "Epoch [10/10], Step [25500], Loss: 0.4011 (val:0.8542), Accuracy:87.50% (val:73.33%)\n",
      "Epoch [10/10], Step [25600], Loss: 0.5019 (val:0.3416), Accuracy:85.00% (val:93.33%)\n",
      "Epoch [10/10], Step [25700], Loss: 0.4527 (val:0.4960), Accuracy:86.67% (val:86.67%)\n",
      "Epoch [10/10], Step [25800], Loss: 0.6180 (val:0.5259), Accuracy:80.00% (val:86.67%)\n",
      "Epoch [10/10], Step [25900], Loss: 0.3796 (val:0.6787), Accuracy:86.87% (val:72.00%)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "if torch.cuda.is_available():\n",
    "    net = net.cuda()\n",
    "\n",
    "trainingAcc = [0]\n",
    "testingAcc  = [0]\n",
    "trainingLoss = []\n",
    "testingLoss = []\n",
    "\n",
    "for epoch in range(10):            \n",
    "    gen = load_torch.ImageLoader(classes=load.classes_1+load.classes_2+load.classes_3+load.classes_4,root_location=data_folder,read_size=32,batch_size=150)\n",
    "    for i, (images, labels) in enumerate(gen):\n",
    "        \n",
    "        vsplit = int(images.shape[0]*0.8)\n",
    "        \n",
    "        xtrain = images[:vsplit].cuda()\n",
    "        ltrain = labels[:vsplit].cuda()\n",
    "        \n",
    "        xtest  = images[vsplit:].cuda()\n",
    "        ltest  = labels[vsplit:].cuda()\n",
    "        \n",
    "        # Forward pass\n",
    "        ypred = net(xtrain)\n",
    "        loss = criterion(ypred, ltrain)\n",
    "        train_acc  = 100 * np.mean(ltrain.data.cpu().numpy() == ypred.cpu().data.numpy ().T.argmax(axis =0))\n",
    "        train_loss = loss.item()\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        ypred = net(xtest)\n",
    "        loss = criterion(ypred, ltest)\n",
    "        test_acc  = 100 * np.mean(ltest.data.cpu().numpy() == ypred.cpu().data.numpy ().T.argmax(axis =0))\n",
    "        test_loss = loss.item()\n",
    "        \n",
    "        del images\n",
    "        del labels\n",
    "        del ypred\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}], Loss: {:.4f} (val:{:.4f}), Accuracy:{:.2f}% (val:{:.2f}%)' .format(epoch+1, T, i+1, train_loss, test_loss, train_acc, test_acc))\n",
    "            #model.save_state_dict('mytraining.pt')\n",
    "     \n",
    "            trainingAcc.append((0.1*train_acc) + (0.9*trainingAcc[-1]))\n",
    "            trainingLoss.append(train_loss)\n",
    "            testingAcc.append((0.1*test_acc) + (0.9*testingAcc[-1]))\n",
    "            testingLoss.append(test_loss)\n",
    "            \n",
    "            #saving parameters/accuracies/losses\n",
    "            torch.save(net.state_dict(), \"Inception CNN/32 classes/inception_cnn_32.pt\")\n",
    "            with open(\"Inception CNN/32 classes/inception_cnn_32_training_acc\", 'wb') as f:\n",
    "                pickle.dump(trainingAcc, f)\n",
    "            with open(\"Inception CNN/32 classes/inception_cnn_32_val_acc\", 'wb') as f:\n",
    "                pickle.dump(testingAcc, f)\n",
    "            with open(\"Inception CNN/32 classes/inception_cnn_32_training_loss\", 'wb') as f:\n",
    "                pickle.dump(trainingLoss, f)\n",
    "            with open(\"Inception CNN/32 classes/inception_cnn_32_val_loss\", 'wb') as f:\n",
    "                pickle.dump(testingLoss, f)\n",
    "            with open(\"Inception CNN/32 classes/current_epoch\", 'wb') as f:\n",
    "                pickle.dump(epoch, f)\n",
    "            with open(\"Inception CNN/32 classes/current_step\", 'wb') as f:\n",
    "                pickle.dump(i, f)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
